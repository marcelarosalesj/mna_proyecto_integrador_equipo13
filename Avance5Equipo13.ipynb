{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Proyecto Integrador - Avance 5. Modelo Final**\n",
        "## **Tecnologico de Monterrey**\n",
        "------------------------------------------------------------------\n",
        "### Profa. Dra. Grettel Barceló Alonso\n",
        "\n",
        "### Prof. Dr. Luis Eduardo Falcón Morales\n",
        "\n",
        "### Profa. Verónica Sandra Guzmán de Valle\n",
        "------------------------------------------------------------------\n",
        "### Marcela Alejandra Rosales Jiménez - A01032022\n",
        "### José Antonio Mendoza Castro - A01794067"
      ],
      "metadata": {
        "id": "UqYDsqYEVxkk"
      },
      "id": "UqYDsqYEVxkk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Resumen**"
      ],
      "metadata": {
        "id": "hxzc8I-VXU7_"
      },
      "id": "hxzc8I-VXU7_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **En el presente Notebook se busca analizar la base de datos *Woven Traffic Safety* (WTS) la cual fue usada en *The 8th AI City Challange* realizado en 2024, el objetivo es poder presentar herramientas de Inteligencia Artificial que permitan disminuir conflictos viales. La base consta de videos y transcripciones de los mismos en los que se muestran eventos actuados entre peatones, ciclistas y automoviles. Para el analisis se obtuvierion nuevas transcripciones de los videos utilizando Gemini en un Notebook de Colab Enterprise de Google Cloud Platform (GCP) para una muestra aleatoria de 150 videos. Se utilizaron los siguientes prompts para la generacion de las nuevas transcripciones:**\n",
        "\n",
        "*   #### **Look through each frame in the video carefully and answer the question.**\n",
        "*   #### **Only base your answers strictly on what information is available in the video attached.**\n",
        "*   #### **Do not make up any information that is not part of the video and do not be too verbose.**\n",
        "*   #### **Questions:**\n",
        "*   #### **Give me a detail description of the video, related to the safety of pedestrians with respect to vehicles.**\n",
        "*   #### **In the video, is there a collision or accident (contact or hit between pedestrians and vehicles) for pedestrians with respect to vehicles?**\n",
        "\n",
        "#### **Una vez listos los nuevos textos se prosiguio con el analisis en el se prueba:**\n",
        "\n",
        "\n",
        "*   #### **Regresion Logistica**\n",
        "*   #### **Red Neuronal**\n",
        "*   #### **fastText**\n",
        "*   #### **Zero-shot con la libreria Transformers**\n",
        "\n",
        "#### **Para evaluar la clasificacion se utilizan las metricas Accuracy y Recall. Finalmente se llega a que la clasificacion obtenida con el Zero-shot tiene la mejor ejecucion y que podria ser explorada con mayor profundidad en analisis futuros.**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "te9CmyC0XYDc"
      },
      "id": "te9CmyC0XYDc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Preparacion del ambiente**"
      ],
      "metadata": {
        "id": "zycprDxMWTgx"
      },
      "id": "zycprDxMWTgx"
    },
    {
      "cell_type": "code",
      "id": "o4RCM2MqbrXgbM3X51RszhbI",
      "metadata": {
        "tags": [],
        "id": "o4RCM2MqbrXgbM3X51RszhbI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730333344000,
          "user_tz": 360,
          "elapsed": 22507,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "4f73e37e-4481-4cda-8438-ce24b786d00c"
      },
      "source": [
        "!pip install --upgrade google-cloud-aiplatform"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (1.70.0)\n",
            "Collecting google-cloud-aiplatform\n",
            "  Downloading google_cloud_aiplatform-1.71.0-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.19.2)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (24.1)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.12.5)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.0.6)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.9.2)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.65.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
            "Requirement already satisfied: numpy<3,>=1.14 in /usr/local/lib/python3.10/dist-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.26.4)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.6.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.8.30)\n",
            "Downloading google_cloud_aiplatform-1.71.0-py2.py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: google-cloud-aiplatform\n",
            "  Attempting uninstall: google-cloud-aiplatform\n",
            "    Found existing installation: google-cloud-aiplatform 1.70.0\n",
            "    Uninstalling google-cloud-aiplatform-1.70.0:\n",
            "      Successfully uninstalled google-cloud-aiplatform-1.70.0\n",
            "Successfully installed google-cloud-aiplatform-1.71.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "458e08947c2a47ed92bbeabaa744da59"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6Q59WjXIBWJ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730504887836,
          "user_tz": 360,
          "elapsed": 52552,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "d4f0076d-b8a7-4a58-cdde-b93c00cae547"
      },
      "id": "N6Q59WjXIBWJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (69.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.26.4)\n",
            "Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp310-cp310-linux_x86_64.whl size=4296187 sha256=0aed579ecdf8c045876967b51e20e1602730dea7a6892f4483d6c2de4f322fb4\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/a2/00/81db54d3e6a8199b829d58e02cec2ddb20ce3e59fad8d3c92a\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-2.13.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth application-default login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuZjbvNk5sBS",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730333427480,
          "user_tz": 360,
          "elapsed": 49658,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "c08add40-53ec-4ef8-a4ca-e6594893ecb4"
      },
      "id": "nuZjbvNk5sBS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are running on a Google Compute Engine virtual machine.\n",
            "The service credentials associated with this virtual machine\n",
            "will automatically be used by Application Default\n",
            "Credentials, so it is not necessary to use this command.\n",
            "\n",
            "If you decide to proceed anyway, your user credentials may be visible\n",
            "to others with access to this virtual machine. Are you sure you want\n",
            "to authenticate with your personal account?\n",
            "\n",
            "Do you want to continue (Y/n)?  Y\n",
            "\n",
            "Go to the following link in your browser, and complete the sign-in prompts:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=AUtl3HTBf2pjpT5CuwkODomGgHetrP&prompt=consent&token_usage=remote&access_type=offline&code_challenge=s-Y9AA3VLkRPvCQr2yG9FQZGBdHtCdMWp-NWVgCxZ6M&code_challenge_method=S256\n",
            "\n",
            "Once finished, enter the verification code provided in your browser: 4/0AVG7fiS84wgmHm3Y9rwmhnVfNWvrrkmywUm6-_qd27ACkl575sX5vO4x3Eh_P2eBTUS_4g\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\n",
            "Quota project \"project-team-13\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Librerias**"
      ],
      "metadata": {
        "id": "ljHEECOwWcrp"
      },
      "id": "ljHEECOwWcrp"
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import base64\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, recall_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.tag import pos_tag\n",
        "import tensorflow as tf\n",
        "from transformers import pipeline, BertTokenizer, TFBertForSequenceClassification\n",
        "import torch\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.metrics import Recall\n",
        "import fasttext\n",
        "from google.cloud import storage\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part, SafetySetting"
      ],
      "metadata": {
        "id": "GN_j5EE_GZJy",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730578883997,
          "user_tz": 360,
          "elapsed": 12030,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "GN_j5EE_GZJy",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_seq_items', None)"
      ],
      "metadata": {
        "id": "H5u183Sj6zhg",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730578883997,
          "user_tz": 360,
          "elapsed": 7,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "H5u183Sj6zhg",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Funciones**"
      ],
      "metadata": {
        "id": "_bOGj9wXRO5p"
      },
      "id": "_bOGj9wXRO5p"
    },
    {
      "cell_type": "code",
      "source": [
        "def list_blobs_prefix(bucket_name, prefix):\n",
        "  \"\"\"\n",
        "  Funcion que obtiene los path en un folder de un bucket de cloud storage.\n",
        "  \"\"\"\n",
        "  list_tmp = []\n",
        "\n",
        "  storage_client = storage.Client()\n",
        "\n",
        "  blobs = storage_client.list_blobs(bucket_name, prefix=prefix)\n",
        "\n",
        "  for blob in blobs:\n",
        "    list_tmp.append(f\"gs://{bucket_name}/{blob.name}\")\n",
        "\n",
        "  return list_tmp"
      ],
      "metadata": {
        "id": "dfHBF0RTNrR6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730578883997,
          "user_tz": 360,
          "elapsed": 6,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "dfHBF0RTNrR6",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate():\n",
        "  \"\"\"\n",
        "  Funcion que genera un caption de un video.\n",
        "  \"\"\"\n",
        "\n",
        "  caption_tmp = \"\"\n",
        "\n",
        "  vertexai.init(project='project-team-13', location='us-central1')\n",
        "  model = GenerativeModel(\n",
        "      \"gemini-1.5-flash-002\",\n",
        "  )\n",
        "  responses = model.generate_content(\n",
        "      [video1, text1],\n",
        "      generation_config=generation_config,\n",
        "      safety_settings=safety_settings,\n",
        "      stream=True,\n",
        "  )\n",
        "\n",
        "  for response in responses:\n",
        "    caption_tmp += response.text\n",
        "\n",
        "  return caption_tmp"
      ],
      "metadata": {
        "id": "u8uuJYG7pd8f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730578883997,
          "user_tz": 360,
          "elapsed": 6,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "u8uuJYG7pd8f",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_caption(text):\n",
        "  \"\"\"\n",
        "  Funcion que separa el caption de acuerdo a los caracteres '**'.\n",
        "  \"\"\"\n",
        "  split_items= text.split('**')\n",
        "  if len(split_items) == 5:\n",
        "    return [split_items[2], split_items[4]]\n",
        "  else:\n",
        "    return [None] * 2"
      ],
      "metadata": {
        "id": "2wqhSrosW2TQ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730578883998,
          "user_tz": 360,
          "elapsed": 6,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "2wqhSrosW2TQ",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_pos_tags(text):\n",
        "  \"\"\"\n",
        "  Funcion que agrega pos tags para agregar mas contexto a las palabras.\n",
        "  \"\"\"\n",
        "  tagged_words = pos_tag(nltk.word_tokenize(text))\n",
        "  return ' '.join([word + '_' + tag for word, tag in tagged_words])"
      ],
      "metadata": {
        "id": "x46XgzXaAzWE",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730578883998,
          "user_tz": 360,
          "elapsed": 6,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "x46XgzXaAzWE",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(text):\n",
        "  \"\"\"\n",
        "  Funcion que obtiene las features previo a aplicar una clsificacion.\n",
        "  \"\"\"\n",
        "  inputs = tokenizerZS(text, return_tensors='tf')\n",
        "  outputs = modelZS(**inputs)\n",
        "  features = outputs.logits\n",
        "  return features.numpy().flatten()"
      ],
      "metadata": {
        "id": "zRlCfdjKYrDL",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730578883998,
          "user_tz": 360,
          "elapsed": 5,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "zRlCfdjKYrDL",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_text(text, candidate_collision_labels_tmp, candidate_no_collision_labels_tmp):\n",
        "  \"\"\"\n",
        "  Funcion que clasifica un texto a partir de un zero-shot classifier.\n",
        "  \"\"\"\n",
        "  result_1 = classifier(text, candidate_collision_labels_tmp)\n",
        "  result_2 = classifier(text, candidate_no_collision_labels_tmp)\n",
        "  if result_1['scores'][0] > result_2['scores'][0]:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "metadata": {
        "id": "bzAONVagHCKn",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730578883998,
          "user_tz": 360,
          "elapsed": 5,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "bzAONVagHCKn",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Generacion de captions con Gemini para una muestra de videos**"
      ],
      "metadata": {
        "id": "tGOr98OEPlgR"
      },
      "id": "tGOr98OEPlgR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta seccion se generan nuevas transcripciones con Gemini en Vertex de GCP. Se selecciona una muestra aleatoria de 150 videos."
      ],
      "metadata": {
        "id": "TPqQ3yB6d-Bp"
      },
      "id": "TPqQ3yB6d-Bp"
    },
    {
      "cell_type": "code",
      "source": [
        "list_video_train_paths = list_blobs_prefix('bucket-video-wts', 'train/')"
      ],
      "metadata": {
        "id": "IPr4z1dY6VRO"
      },
      "id": "IPr4z1dY6VRO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_path_train = [path for path in list_video_train_paths if 'normal_trimmed' not in path]"
      ],
      "metadata": {
        "id": "1Wdu5brpXIPJ"
      },
      "id": "1Wdu5brpXIPJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_video_val_paths = list_blobs_prefix('bucket-video-wts', 'val/')"
      ],
      "metadata": {
        "id": "07OurbgaWaPZ"
      },
      "id": "07OurbgaWaPZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_path_val = [path for path in list_video_val_paths if 'normal_trimmed' not in path]"
      ],
      "metadata": {
        "id": "dAQ3bNr-GKOz"
      },
      "id": "dAQ3bNr-GKOz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_path = list_path_train + list_path_val"
      ],
      "metadata": {
        "id": "M9QnEjTnGWMD"
      },
      "id": "M9QnEjTnGWMD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_sample_path = random.sample(list_path[1:], 150)"
      ],
      "metadata": {
        "id": "mVEgz6UvW87W"
      },
      "id": "mVEgz6UvW87W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_video_captions = []\n",
        "\n",
        "for gcs_path in list_sample_path:\n",
        "\n",
        "  video1 = Part.from_uri(\n",
        "      mime_type=\"video/mp4\",\n",
        "      uri=gcs_path\n",
        "  )\n",
        "\n",
        "  text1 = \"\"\"Look through each frame in the video carefully and answer the question.\n",
        "    Only base your answers strictly on what information is available in the video attached.\n",
        "    Do not make up any information that is not part of the video and do not be too verbose.\n",
        "\n",
        "    Questions:\n",
        "    - Give me a detail description of the video, related to the safety of pedestrians with respect to vehicles.\n",
        "    - In the video, is there a collision or accident (contact or hit between pedestrians and vehicles) for pedestrians with respect to vehicles?\"\"\"\n",
        "\n",
        "  generation_config = {\n",
        "      \"max_output_tokens\": 8192,\n",
        "      \"temperature\": 1,\n",
        "      \"top_p\": 0.95\n",
        "  }\n",
        "\n",
        "  safety_settings = [\n",
        "      SafetySetting(\n",
        "          category=SafetySetting.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
        "          threshold=SafetySetting.HarmBlockThreshold.OFF\n",
        "      ),\n",
        "      SafetySetting(\n",
        "          category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
        "          threshold=SafetySetting.HarmBlockThreshold.OFF\n",
        "      ),\n",
        "      SafetySetting(\n",
        "          category=SafetySetting.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
        "          threshold=SafetySetting.HarmBlockThreshold.OFF\n",
        "      ),\n",
        "      SafetySetting(\n",
        "          category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
        "          threshold=SafetySetting.HarmBlockThreshold.OFF\n",
        "      )\n",
        "  ]\n",
        "\n",
        "  list_video_captions.append(generate())"
      ],
      "metadata": {
        "id": "Sof_NiMVuzf1"
      },
      "id": "Sof_NiMVuzf1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions = pd.DataFrame(data=zip(list_sample_path, list_video_captions), columns=['path', 'caption'])"
      ],
      "metadata": {
        "id": "2EG30yuVzvxJ"
      },
      "id": "2EG30yuVzvxJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Analisis de los datos**"
      ],
      "metadata": {
        "id": "czS7YDhxGISy"
      },
      "id": "czS7YDhxGISy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta seccion se genera un pandas dataframe con el que se probaran algunos modelos posteriormente."
      ],
      "metadata": {
        "id": "IIqiH2f7gRRe"
      },
      "id": "IIqiH2f7gRRe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se da una primer visualizacion de los datos."
      ],
      "metadata": {
        "id": "y2VlWY29GnmT"
      },
      "id": "y2VlWY29GnmT"
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions = pd.read_csv('gemini_video_captions3.csv')"
      ],
      "metadata": {
        "id": "5NsWVRnzr5kB"
      },
      "id": "5NsWVRnzr5kB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "93pOjpWCGSWL",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730497515762,
          "user_tz": 360,
          "elapsed": 6,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "88067b67-6bc0-470a-ae4d-d6aa00c88eac"
      },
      "id": "93pOjpWCGSWL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                   path  \\\n",
              "0     gs://bucket-video-wts/train/20230929_68_SN32_T1/vehicle_view/20230929_68_SN32_T1_vehicle_view.mp4   \n",
              "1  gs://bucket-video-wts/train/20231006_34_CN24_T1/overhead_view/20231006_34_CN24_T1_192.168.0.13_4.mp4   \n",
              "2       gs://bucket-video-wts/train/20230707_25_SY1_T1/vehicle_view/20230707_25_SY1_T1_vehicle_view.mp4   \n",
              "3    gs://bucket-video-wts/val/20230922_19_CN13_T1/overhead_view/20230922_19_CN13_T1_192.168.0.12_3.mp4   \n",
              "4      gs://bucket-video-wts/val/20230922_32_CN3_T1/overhead_view/20230922_32_CN3_T1_192.168.0.12_4.mp4   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       caption  \n",
              "0                                                                                      Here's a description of the video based on your questions:\\n\\nThe video shows a car approaching a crosswalk at night. Several pedestrians are crossing the road. One pedestrian appears to briefly stop in front of the car, then continue walking. The car slows down but does not stop completely.  The road is relatively dark with streetlights and there is a traffic signal visible.\\n\\n\\nThere is no collision or accident between the pedestrians and the vehicle in the video.  \n",
              "1                                                                                               Here are the answers based on the provided video:\\n\\n**Description of the video related to pedestrian safety:**\\n\\nThe video shows a pedestrian crossing at an intersection with pedestrian crosswalks clearly marked. Two pedestrians are crossing the road while a bicycle is parked near the crosswalk.  No vehicles are present during the video.\\n\\n**Collision or accident?**\\n\\nNo, there is no collision or accident between pedestrians and vehicles in this video.\\n  \n",
              "2                                  Here are the answers based on the provided video:\\n\\n**Description of pedestrian safety:** The video shows a car approaching a pedestrian crossing.  Pedestrians are crossing the street while the traffic light is green for vehicles.  A person is seen bending over near the road as the vehicle passes, with a person holding an umbrella nearby.  The vehicles stop before the crosswalk for the pedestrians to cross.\\n\\n**Collision/Accident:** No, there is no collision or accident between pedestrians and vehicles in the video.  \n",
              "3  Here are the answers based on the provided video:\\n\\n- **Description:** The video shows a high-angle, wide view of a driving test area or similar location with various road markings.  Pedestrians are crossing a crosswalk while a white car is slowly approaching and stopping to allow the pedestrians to cross safely. Another pedestrian is walking near the roadway.\\n\\n- **Collision/Accident:** No.  There is no collision or accident between pedestrians and the vehicle shown in the video. The car stops for the pedestrians, and they cross without incident.  \n",
              "4                                                     Here are the answers based on the provided video:\\n\\n**Description of the video related to pedestrian safety:** The video shows a driving school or similar area with marked pedestrian crossings.  A car approaches and stops at the crosswalk while pedestrians cross. The pedestrians and driver appear to follow traffic rules, demonstrating safe interaction between pedestrians and vehicles.\\n\\n\\n**Collision/Accident:** No, there is no collision or accident between pedestrians and vehicles in the video.\\n  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-08af473a-eb1b-4038-ad1a-51feeab502ce\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>caption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gs://bucket-video-wts/train/20230929_68_SN32_T1/vehicle_view/20230929_68_SN32_T1_vehicle_view.mp4</td>\n",
              "      <td>Here's a description of the video based on your questions:\\n\\nThe video shows a car approaching a crosswalk at night. Several pedestrians are crossing the road. One pedestrian appears to briefly stop in front of the car, then continue walking. The car slows down but does not stop completely.  The road is relatively dark with streetlights and there is a traffic signal visible.\\n\\n\\nThere is no collision or accident between the pedestrians and the vehicle in the video.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gs://bucket-video-wts/train/20231006_34_CN24_T1/overhead_view/20231006_34_CN24_T1_192.168.0.13_4.mp4</td>\n",
              "      <td>Here are the answers based on the provided video:\\n\\n**Description of the video related to pedestrian safety:**\\n\\nThe video shows a pedestrian crossing at an intersection with pedestrian crosswalks clearly marked. Two pedestrians are crossing the road while a bicycle is parked near the crosswalk.  No vehicles are present during the video.\\n\\n**Collision or accident?**\\n\\nNo, there is no collision or accident between pedestrians and vehicles in this video.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gs://bucket-video-wts/train/20230707_25_SY1_T1/vehicle_view/20230707_25_SY1_T1_vehicle_view.mp4</td>\n",
              "      <td>Here are the answers based on the provided video:\\n\\n**Description of pedestrian safety:** The video shows a car approaching a pedestrian crossing.  Pedestrians are crossing the street while the traffic light is green for vehicles.  A person is seen bending over near the road as the vehicle passes, with a person holding an umbrella nearby.  The vehicles stop before the crosswalk for the pedestrians to cross.\\n\\n**Collision/Accident:** No, there is no collision or accident between pedestrians and vehicles in the video.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gs://bucket-video-wts/val/20230922_19_CN13_T1/overhead_view/20230922_19_CN13_T1_192.168.0.12_3.mp4</td>\n",
              "      <td>Here are the answers based on the provided video:\\n\\n- **Description:** The video shows a high-angle, wide view of a driving test area or similar location with various road markings.  Pedestrians are crossing a crosswalk while a white car is slowly approaching and stopping to allow the pedestrians to cross safely. Another pedestrian is walking near the roadway.\\n\\n- **Collision/Accident:** No.  There is no collision or accident between pedestrians and the vehicle shown in the video. The car stops for the pedestrians, and they cross without incident.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gs://bucket-video-wts/val/20230922_32_CN3_T1/overhead_view/20230922_32_CN3_T1_192.168.0.12_4.mp4</td>\n",
              "      <td>Here are the answers based on the provided video:\\n\\n**Description of the video related to pedestrian safety:** The video shows a driving school or similar area with marked pedestrian crossings.  A car approaches and stops at the crosswalk while pedestrians cross. The pedestrians and driver appear to follow traffic rules, demonstrating safe interaction between pedestrians and vehicles.\\n\\n\\n**Collision/Accident:** No, there is no collision or accident between pedestrians and vehicles in the video.\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08af473a-eb1b-4038-ad1a-51feeab502ce')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-08af473a-eb1b-4038-ad1a-51feeab502ce button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-08af473a-eb1b-4038-ad1a-51feeab502ce');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6d7c6c1f-1c62-45f9-8681-6ed27ec0712f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6d7c6c1f-1c62-45f9-8681-6ed27ec0712f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6d7c6c1f-1c62-45f9-8681-6ed27ec0712f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se eliminan los saltos de renglon '\\n'."
      ],
      "metadata": {
        "id": "vH2gxTzXGaqM"
      },
      "id": "vH2gxTzXGaqM"
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions['caption'] = df_gemini_captions['caption'].str.replace('\\n', '', regex=True)"
      ],
      "metadata": {
        "id": "TgbF-aKR8JN5"
      },
      "id": "TgbF-aKR8JN5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se observa las preguntas hechas a Gemini en general quedan delimitadas por dos asteriscos '**'. Por lo que dividimos cada texto con respecto a esos caracteres."
      ],
      "metadata": {
        "id": "BQmfNsODGlqy"
      },
      "id": "BQmfNsODGlqy"
    },
    {
      "cell_type": "code",
      "source": [
        "list_captions = []\n",
        "\n",
        "for cap in df_gemini_captions['caption']:\n",
        "  list_captions.append(cap.split('**'))"
      ],
      "metadata": {
        "id": "XPRDWrp56iqH"
      },
      "id": "XPRDWrp56iqH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En principio se esperarian 5 elementos por lista. El primero introduciendo la descripcion, el segundo el titulo de la descripcion, el tercero la descripcion, el cuarto el titulo del evento 'accidente/colision' y quinto la afirmacion/negacion de ese evento."
      ],
      "metadata": {
        "id": "RvYUKbMXN6uN"
      },
      "id": "RvYUKbMXN6uN"
    },
    {
      "cell_type": "code",
      "source": [
        "dict_count = {}\n",
        "\n",
        "for l in list_captions:\n",
        "  lenght = len(l)\n",
        "  if lenght in dict_count:\n",
        "    dict_count[lenght] += 1\n",
        "  else:\n",
        "    dict_count[lenght] = 1"
      ],
      "metadata": {
        "id": "ZamNnkD_CLNo"
      },
      "id": "ZamNnkD_CLNo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "De los 150 textos disponibles, 134 cumplen con el comportamiento esperado por lo que se separan ambos textos dos nuevas columnas."
      ],
      "metadata": {
        "id": "nW7qxtVqP4vt"
      },
      "id": "nW7qxtVqP4vt"
    },
    {
      "cell_type": "code",
      "source": [
        "dict_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxAbTnUYCMyk",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730429793865,
          "user_tz": 360,
          "elapsed": 598,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "3908e5a7-1062-4ccc-b518-72e5a4257a33"
      },
      "id": "cxAbTnUYCMyk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 14, 5: 134, 9: 1, 7: 1}"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for l in list_captions:\n",
        "  if len(l) != 5:\n",
        "    print(l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvHR_CNkDWCe",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730429851889,
          "user_tz": 360,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "3d36d4c8-7f41-4e15-c0d3-22073071b9ad"
      },
      "id": "SvHR_CNkDWCe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Here's a description of the video based on your questions:The video shows a car approaching a crosswalk at night. Several pedestrians are crossing the road. One pedestrian appears to briefly stop in front of the car, then continue walking. The car slows down but does not stop completely.  The road is relatively dark with streetlights and there is a traffic signal visible.There is no collision or accident between the pedestrians and the vehicle in the video.\"]\n",
            "[\"Here's a description of the video concerning pedestrian safety and whether a collision occurred:The video shows a car driving at night on a road with minimal traffic. Pedestrians are seen crossing the road in front of the vehicle; however, the driver slows down and safely passes them without incident.  A person briefly appears to be sitting on the car's hood.There is no collision or accident between pedestrians and vehicles shown in the video.\"]\n",
            "[\"Here's a description of the video regarding pedestrian safety and whether a collision occurred:The video shows a driving test area.  Pedestrians are crossing a marked crosswalk. A car approaches the crosswalk and stops to allow the pedestrians to cross.  The car then proceeds after pedestrians have crossed.No collision or accident occurs between pedestrians and the vehicle.\"]\n",
            "['Here are the answers based on the provided video:- The video shows a pedestrian crossing at a traffic intersection with pedestrian crosswalks and traffic signals. A white car approaches the crosswalk while pedestrians are crossing, but the car stops to allow them to proceed safely. The traffic light is red for the car.- No, there is no collision or accident between pedestrians and vehicles in the video.']\n",
            "['Here are the answers based on the provided video:- The video shows a pedestrian crossing with traffic signals.  Pedestrians are seen crossing only when the traffic signal is green for pedestrians (and red for vehicles).  There are clearly marked pedestrian crossings.- No, there is no collision or accident between pedestrians and vehicles in the video.']\n",
            "['Here are the answers based on the provided video:- The video shows a driving test course. Pedestrians are crossing a marked crosswalk. A car approaches and stops to allow pedestrians to cross safely.  The car then proceeds after the pedestrians have completely crossed.- No, there is no collision or accident between pedestrians and vehicles in the video.']\n",
            "[\"Here's a description of the video concerning pedestrian safety and whether a collision occurs:The video shows a person on a skateboard crossing a road in a driving school area. A car is approaching the pedestrian, who stops before reaching the vehicle.  The car stops, and the pedestrian appears to talk to the driver before continuing across the road.No collision or accident occurs between the pedestrian and the vehicle.\"]\n",
            "['Here are the answers based on the provided video:- The video shows a relatively empty intersection with pedestrians crossing a crosswalk.  A car approaches the intersection and stops before the crosswalk while pedestrians are crossing. Pedestrians cross the crosswalk and the car waits until they have completed their crossing before proceeding through the intersection. The traffic light is red for vehicles while pedestrians are crossing.- No, there is no collision or accident between pedestrians and vehicles in the video.']\n",
            "[\"Here's a description of the video concerning pedestrian safety and whether a collision occurs:The video shows a scene at what appears to be a driving school or test area.  A white car stops to allow pedestrians to cross the road. Pedestrians are then shown walking toward the car and passing it without incident. One person appears to be using a cell phone while waiting to cross.  There is no collision between any pedestrian and any vehicle.\"]\n",
            "[\"Here's a description of the video based on your questions:The video shows a street intersection with pedestrians and cyclists crossing.  There is a traffic light present, but the level of adherence to the traffic signals by pedestrians and cyclists is not fully clear. The video is shot from a static point of view and does not show the street from all angles.There is no collision or accident shown in the video between pedestrians or cyclists and vehicles.  However, there is an incident involving a cyclist falling near the crosswalk.\"]\n",
            "['Here are the answers based on the provided video:- The video shows a pedestrian crossing at a crosswalk.  A cyclist also crosses the road at the crosswalk.  Traffic signals are present to regulate the traffic and pedestrian flow. The video shows the traffic light turning red allowing pedestrians to cross safely.- No, there is no collision or accident shown in the video.']\n",
            "['Here are the answers based on the provided video:- The video shows a car approaching a pedestrian crossing. Two pedestrians are waiting at the crossing, and the traffic light is red for the car. The car stops, allowing the pedestrians to cross safely.- No, there is no collision or accident between pedestrians and vehicles in the video.']\n",
            "[\"Here's a description of the video concerning pedestrian safety and whether a collision occurred:The video shows a wide shot of a multi-lane intersection with pedestrian crosswalks.  Several pedestrians and a cyclist are using the crosswalks. A white car approaches the intersection while the pedestrians are crossing. The car slows down and safely passes the pedestrians and cyclist in the crosswalk. The traffic light is visible, and it appears to change from red to yellow during the video.No, there is no collision or accident (no contact or hit between pedestrians and vehicles) in the video.\"]\n",
            "[\"Here's a description of the video and answers to your questions:\", 'Video Description:', 'The video shows a driving test area.  Several people are practicing driving maneuvers in cars and on bicycles. Pedestrians are also present in the area.  Some pedestrians walk near the vehicles, and at one point, a cyclist nearly collides with a car.', 'Questions:', '- ', 'Pedestrian Safety:', ' The video shows several instances where pedestrian safety is not prioritized. Pedestrians are walking near moving vehicles without clear separation or right-of-way. A cyclist nearly collides with a car because he has no safe zone to use.- ', 'Collision/Accident:', ' No direct collision or accident between pedestrians and vehicles occurs in the video. However, a near miss happens between a cyclist and a car.']\n",
            "[\"Here are the answers based on the provided video:- The video shows a car's rear view, looking out at a seemingly empty driving range or similar area.  There are no pedestrians visible in the driving range area, and no indication of pedestrian crossings or walkways. There is a fence separating the driving range and the road, suggesting a measure to protect pedestrians.- No, there is no collision or accident between pedestrians and vehicles shown in the video.\"]\n",
            "[\"Here's a description of the video and answers to your questions:\", 'Video Description:', ' The video shows a high-angle view of a road intersection with pedestrian crosswalks. Several pedestrians are crossing the road at different times. A white car approaches the intersection and stops to allow pedestrians to cross before continuing.', 'Pedestrian Safety:', ' The video shows a scenario where drivers yield to pedestrians in a crosswalk, and pedestrians appear to be aware of oncoming traffic.', 'Collision/Accident:', ' No, there is no collision or accident between pedestrians and vehicles in the video.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se valida que las listas con 5 elementos tengan el comportamiento esperado."
      ],
      "metadata": {
        "id": "3Wl31pIiRdq-"
      },
      "id": "3Wl31pIiRdq-"
    },
    {
      "cell_type": "code",
      "source": [
        "for l in list_captions:\n",
        "  if len(l) == 5:\n",
        "    print(l[1], ' - ', l[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVQZwZ72Eeht",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730429903089,
          "user_tz": 360,
          "elapsed": 260,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "36b7910f-6b4a-4ce2-de12-7006023fcff0"
      },
      "id": "GVQZwZ72Eeht",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Description of the video related to pedestrian safety:  -  Collision or accident?\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision/Accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision or accident:\n",
            "Description of pedestrian safety:  -  Collision/accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision or accident?:\n",
            "Description:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision or accident?:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision or accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision/Accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision or accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision or accident:\n",
            "Pedestrian Safety:  -  Collision/Accident:\n",
            "Video Description:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/accident:\n",
            "Pedestrian Safety:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Pedestrian Safety Description:  -  Collision/Accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision or accident:\n",
            "Pedestrian Safety:  -  Collision/Accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision/accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Pedestrian Safety:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/accident:\n",
            "Description of pedestrian safety:  -  Collision/accident?:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Video Description:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision/accident:\n",
            "Description of Pedestrian Safety:  -  Collision/Accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision or accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision or accident:\n",
            "Video Description:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision or accident?:\n",
            "Description of the video related to pedestrian safety:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision or accident?:\n",
            "Description of pedestrian safety:  -  Collision or accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Pedestrian Safety Description:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/accident:\n",
            "Description of pedestrian safety:  -  Collision/accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision/accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision or accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/accident:\n",
            "Pedestrian Safety:  -  Collision/Accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision or accident?\n",
            "Description of pedestrian safety:  -  Collision/accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Pedestrian Safety:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision or accident?:\n",
            "Description of pedestrian safety:  -  Collision/accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision or accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Pedestrian Safety Description:  -  Collision/Accident?:\n",
            "Description of the video related to pedestrian safety:  -  Collision or accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision or accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident?:\n",
            "Video Description:  -  Collision/Accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision or accident:\n",
            "Pedestrian Safety:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision/Accident:\n",
            "Pedestrian Safety:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/accident:\n",
            "Description:  -  Collision/Accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision/Accident:\n",
            "Pedestrian Safety:  -  Collision/Accident:\n",
            "Description of pedestrian safety:  -  Collision/Accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision or accident?:\n",
            "Description of the video related to pedestrian safety:  -  Collision/Accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision/accident:\n",
            "Description of the video related to pedestrian safety:  -  Collision or accident:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se crean dos nuevas columnas."
      ],
      "metadata": {
        "id": "Pi85_bnKS11v"
      },
      "id": "Pi85_bnKS11v"
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions[['description', 'collision/accident']] = df_gemini_captions['caption'].apply(lambda x: pd.Series(split_caption(x)))"
      ],
      "metadata": {
        "id": "78sdJ6BCTQ3S"
      },
      "id": "78sdJ6BCTQ3S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validamos los valores que quedaron en 'None'."
      ],
      "metadata": {
        "id": "9vLt1T-QsciQ"
      },
      "id": "9vLt1T-QsciQ"
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions[df_gemini_captions['description'].isnull()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-EX6N9-ZTTf2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730430397418,
          "user_tz": 360,
          "elapsed": 289,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "f2353444-874c-4888-c4c5-ad11ae814eaf"
      },
      "id": "-EX6N9-ZTTf2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                     path  \\\n",
              "0       gs://bucket-video-wts/train/20230929_68_SN32_T1/vehicle_view/20230929_68_SN32_T1_vehicle_view.mp4   \n",
              "6         gs://bucket-video-wts/val/20230728_60_SY11_T1/vehicle_view/20230728_60_SY11_T1_vehicle_view.mp4   \n",
              "11        gs://bucket-video-wts/train/20230728_31_CN37_T1/overhead_view/20230728_31_CN37_T1_Camera3_1.mp4   \n",
              "23     gs://bucket-video-wts/train/20230922_38_CN7_T1/overhead_view/20230922_38_CN7_T1_192.168.0.11_1.mp4   \n",
              "24   gs://bucket-video-wts/train/20230922_47_SN37_T1/overhead_view/20230922_47_SN37_T1_192.168.0.11_1.mp4   \n",
              "41          gs://bucket-video-wts/val/20230728_27_CN34_T1/overhead_view/20230728_27_CN34_T1_Camera3_1.mp4   \n",
              "68   gs://bucket-video-wts/train/20231006_25_SN20_T1/overhead_view/20231006_25_SN20_T1_192.168.0.12_2.mp4   \n",
              "72          gs://bucket-video-wts/train/20230707_19_CN8_T1/overhead_view/20230707_19_CN8_T1_Camera1_0.mp4   \n",
              "73        gs://bucket-video-wts/train/20230728_29_SN16_T1/overhead_view/20230728_29_SN16_T1_Camera3_1.mp4   \n",
              "95        gs://bucket-video-wts/val/20230922_29_CN18_T1/vehicle_view/20230922_29_CN18_T1_vehicle_view.mp4   \n",
              "98        gs://bucket-video-wts/val/20230929_41_CN36_T1/vehicle_view/20230929_41_CN36_T1_vehicle_view.mp4   \n",
              "103       gs://bucket-video-wts/train/20230728_32_CN4_T1/vehicle_view/20230728_32_CN4_T1_vehicle_view.mp4   \n",
              "104    gs://bucket-video-wts/train/20230922_27_CN2_T1/overhead_view/20230922_27_CN2_T1_192.168.0.17_1.mp4   \n",
              "108       gs://bucket-video-wts/train/20230728_40_SN31_T1/overhead_view/20230728_40_SN31_T1_Camera3_1.mp4   \n",
              "121     gs://bucket-video-wts/train/20230929_60_CN16_T1/vehicle_view/20230929_60_CN16_T1_vehicle_view.mp4   \n",
              "134  gs://bucket-video-wts/train/20230929_58_SN40_T1/overhead_view/20230929_58_SN40_T1_192.168.0.13_4.mp4   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           caption  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                    Here's a description of the video based on your questions:The video shows a car approaching a crosswalk at night. Several pedestrians are crossing the road. One pedestrian appears to briefly stop in front of the car, then continue walking. The car slows down but does not stop completely.  The road is relatively dark with streetlights and there is a traffic signal visible.There is no collision or accident between the pedestrians and the vehicle in the video.   \n",
              "6                                                                                                                                                                                                                                                                                                                                                  Here's a description of the video concerning pedestrian safety and whether a collision occurred:The video shows a car driving at night on a road with minimal traffic. Pedestrians are seen crossing the road in front of the vehicle; however, the driver slows down and safely passes them without incident.  A person briefly appears to be sitting on the car's hood.There is no collision or accident between pedestrians and vehicles shown in the video.   \n",
              "11                                                                                                                                                                                                                                                                                                                                                                                                                        Here's a description of the video regarding pedestrian safety and whether a collision occurred:The video shows a driving test area.  Pedestrians are crossing a marked crosswalk. A car approaches the crosswalk and stops to allow the pedestrians to cross.  The car then proceeds after pedestrians have crossed.No collision or accident occurs between pedestrians and the vehicle.   \n",
              "23                                                                                                                                                                                                                                                                                                                                                                                          Here are the answers based on the provided video:- The video shows a pedestrian crossing at a traffic intersection with pedestrian crosswalks and traffic signals. A white car approaches the crosswalk while pedestrians are crossing, but the car stops to allow them to proceed safely. The traffic light is red for the car.- No, there is no collision or accident between pedestrians and vehicles in the video.   \n",
              "24                                                                                                                                                                                                                                                                                                                                                                                                                                               Here are the answers based on the provided video:- The video shows a pedestrian crossing with traffic signals.  Pedestrians are seen crossing only when the traffic signal is green for pedestrians (and red for vehicles).  There are clearly marked pedestrian crossings.- No, there is no collision or accident between pedestrians and vehicles in the video.   \n",
              "41                                                                                                                                                                                                                                                                                                                                                                                                                                             Here are the answers based on the provided video:- The video shows a driving test course. Pedestrians are crossing a marked crosswalk. A car approaches and stops to allow pedestrians to cross safely.  The car then proceeds after the pedestrians have completely crossed.- No, there is no collision or accident between pedestrians and vehicles in the video.   \n",
              "68                                                                                                                                                                                                                                                                                                                                                                         Here's a description of the video concerning pedestrian safety and whether a collision occurs:The video shows a person on a skateboard crossing a road in a driving school area. A car is approaching the pedestrian, who stops before reaching the vehicle.  The car stops, and the pedestrian appears to talk to the driver before continuing across the road.No collision or accident occurs between the pedestrian and the vehicle.   \n",
              "72                                                                                                                                                                                                                                                                  Here are the answers based on the provided video:- The video shows a relatively empty intersection with pedestrians crossing a crosswalk.  A car approaches the intersection and stops before the crosswalk while pedestrians are crossing. Pedestrians cross the crosswalk and the car waits until they have completed their crossing before proceeding through the intersection. The traffic light is red for vehicles while pedestrians are crossing.- No, there is no collision or accident between pedestrians and vehicles in the video.   \n",
              "73                                                                                                                                                                                                                                                                                                                                                     Here's a description of the video concerning pedestrian safety and whether a collision occurs:The video shows a scene at what appears to be a driving school or test area.  A white car stops to allow pedestrians to cross the road. Pedestrians are then shown walking toward the car and passing it without incident. One person appears to be using a cell phone while waiting to cross.  There is no collision between any pedestrian and any vehicle.   \n",
              "95                                                                                                                                                                                                                                                       Here's a description of the video based on your questions:The video shows a street intersection with pedestrians and cyclists crossing.  There is a traffic light present, but the level of adherence to the traffic signals by pedestrians and cyclists is not fully clear. The video is shot from a static point of view and does not show the street from all angles.There is no collision or accident shown in the video between pedestrians or cyclists and vehicles.  However, there is an incident involving a cyclist falling near the crosswalk.   \n",
              "98                                                                                                                                                                                                                                                                                                                                                                                                                            Here are the answers based on the provided video:- The video shows a pedestrian crossing at a crosswalk.  A cyclist also crosses the road at the crosswalk.  Traffic signals are present to regulate the traffic and pedestrian flow. The video shows the traffic light turning red allowing pedestrians to cross safely.- No, there is no collision or accident shown in the video.   \n",
              "103                                                                                                                                                                                                                                                                                                                                                                                                                                                              Here are the answers based on the provided video:- The video shows a car approaching a pedestrian crossing. Two pedestrians are waiting at the crossing, and the traffic light is red for the car. The car stops, allowing the pedestrians to cross safely.- No, there is no collision or accident between pedestrians and vehicles in the video.   \n",
              "104                                                                                                                                                                                           Here's a description of the video concerning pedestrian safety and whether a collision occurred:The video shows a wide shot of a multi-lane intersection with pedestrian crosswalks.  Several pedestrians and a cyclist are using the crosswalks. A white car approaches the intersection while the pedestrians are crossing. The car slows down and safely passes the pedestrians and cyclist in the crosswalk. The traffic light is visible, and it appears to change from red to yellow during the video.No, there is no collision or accident (no contact or hit between pedestrians and vehicles) in the video.   \n",
              "108  Here's a description of the video and answers to your questions:**Video Description:**The video shows a driving test area.  Several people are practicing driving maneuvers in cars and on bicycles. Pedestrians are also present in the area.  Some pedestrians walk near the vehicles, and at one point, a cyclist nearly collides with a car.**Questions:**- **Pedestrian Safety:** The video shows several instances where pedestrian safety is not prioritized. Pedestrians are walking near moving vehicles without clear separation or right-of-way. A cyclist nearly collides with a car because he has no safe zone to use.- **Collision/Accident:** No direct collision or accident between pedestrians and vehicles occurs in the video. However, a near miss happens between a cyclist and a car.   \n",
              "121                                                                                                                                                                                                                                                                                                                                 Here are the answers based on the provided video:- The video shows a car's rear view, looking out at a seemingly empty driving range or similar area.  There are no pedestrians visible in the driving range area, and no indication of pedestrian crossings or walkways. There is a fence separating the driving range and the road, suggesting a measure to protect pedestrians.- No, there is no collision or accident between pedestrians and vehicles shown in the video.   \n",
              "134                                                                                                                                                                                           Here's a description of the video and answers to your questions:**Video Description:** The video shows a high-angle view of a road intersection with pedestrian crosswalks. Several pedestrians are crossing the road at different times. A white car approaches the intersection and stops to allow pedestrians to cross before continuing.**Pedestrian Safety:** The video shows a scenario where drivers yield to pedestrians in a crosswalk, and pedestrians appear to be aware of oncoming traffic.**Collision/Accident:** No, there is no collision or accident between pedestrians and vehicles in the video.   \n",
              "\n",
              "    description collision/accident  \n",
              "0          None               None  \n",
              "6          None               None  \n",
              "11         None               None  \n",
              "23         None               None  \n",
              "24         None               None  \n",
              "41         None               None  \n",
              "68         None               None  \n",
              "72         None               None  \n",
              "73         None               None  \n",
              "95         None               None  \n",
              "98         None               None  \n",
              "103        None               None  \n",
              "104        None               None  \n",
              "108        None               None  \n",
              "121        None               None  \n",
              "134        None               None  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7bdac85e-a092-4311-8e51-3013e8701357\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>caption</th>\n",
              "      <th>description</th>\n",
              "      <th>collision/accident</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gs://bucket-video-wts/train/20230929_68_SN32_T1/vehicle_view/20230929_68_SN32_T1_vehicle_view.mp4</td>\n",
              "      <td>Here's a description of the video based on your questions:The video shows a car approaching a crosswalk at night. Several pedestrians are crossing the road. One pedestrian appears to briefly stop in front of the car, then continue walking. The car slows down but does not stop completely.  The road is relatively dark with streetlights and there is a traffic signal visible.There is no collision or accident between the pedestrians and the vehicle in the video.</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>gs://bucket-video-wts/val/20230728_60_SY11_T1/vehicle_view/20230728_60_SY11_T1_vehicle_view.mp4</td>\n",
              "      <td>Here's a description of the video concerning pedestrian safety and whether a collision occurred:The video shows a car driving at night on a road with minimal traffic. Pedestrians are seen crossing the road in front of the vehicle; however, the driver slows down and safely passes them without incident.  A person briefly appears to be sitting on the car's hood.There is no collision or accident between pedestrians and vehicles shown in the video.</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>gs://bucket-video-wts/train/20230728_31_CN37_T1/overhead_view/20230728_31_CN37_T1_Camera3_1.mp4</td>\n",
              "      <td>Here's a description of the video regarding pedestrian safety and whether a collision occurred:The video shows a driving test area.  Pedestrians are crossing a marked crosswalk. A car approaches the crosswalk and stops to allow the pedestrians to cross.  The car then proceeds after pedestrians have crossed.No collision or accident occurs between pedestrians and the vehicle.</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>gs://bucket-video-wts/train/20230922_38_CN7_T1/overhead_view/20230922_38_CN7_T1_192.168.0.11_1.mp4</td>\n",
              "      <td>Here are the answers based on the provided video:- The video shows a pedestrian crossing at a traffic intersection with pedestrian crosswalks and traffic signals. A white car approaches the crosswalk while pedestrians are crossing, but the car stops to allow them to proceed safely. The traffic light is red for the car.- No, there is no collision or accident between pedestrians and vehicles in the video.</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>gs://bucket-video-wts/train/20230922_47_SN37_T1/overhead_view/20230922_47_SN37_T1_192.168.0.11_1.mp4</td>\n",
              "      <td>Here are the answers based on the provided video:- The video shows a pedestrian crossing with traffic signals.  Pedestrians are seen crossing only when the traffic signal is green for pedestrians (and red for vehicles).  There are clearly marked pedestrian crossings.- No, there is no collision or accident between pedestrians and vehicles in the video.</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>gs://bucket-video-wts/val/20230728_27_CN34_T1/overhead_view/20230728_27_CN34_T1_Camera3_1.mp4</td>\n",
              "      <td>Here are the answers based on the provided video:- The video shows a driving test course. Pedestrians are crossing a marked crosswalk. A car approaches and stops to allow pedestrians to cross safely.  The car then proceeds after the pedestrians have completely crossed.- No, there is no collision or accident between pedestrians and vehicles in the video.</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>gs://bucket-video-wts/train/20231006_25_SN20_T1/overhead_view/20231006_25_SN20_T1_192.168.0.12_2.mp4</td>\n",
              "      <td>Here's a description of the video concerning pedestrian safety and whether a collision occurs:The video shows a person on a skateboard crossing a road in a driving school area. A car is approaching the pedestrian, who stops before reaching the vehicle.  The car stops, and the pedestrian appears to talk to the driver before continuing across the road.No collision or accident occurs between the pedestrian and the vehicle.</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>gs://bucket-video-wts/train/20230707_19_CN8_T1/overhead_view/20230707_19_CN8_T1_Camera1_0.mp4</td>\n",
              "      <td>Here are the answers based on the provided video:- The video shows a relatively empty intersection with pedestrians crossing a crosswalk.  A car approaches the intersection and stops before the crosswalk while pedestrians are crossing. Pedestrians cross the crosswalk and the car waits until they have completed their crossing before proceeding through the intersection. The traffic light is red for vehicles while pedestrians are crossing.- No, there is no collision or accident between pedestrians and vehicles in the video.</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>gs://bucket-video-wts/train/20230728_29_SN16_T1/overhead_view/20230728_29_SN16_T1_Camera3_1.mp4</td>\n",
              "      <td>Here's a description of the video concerning pedestrian safety and whether a collision occurs:The video shows a scene at what appears to be a driving school or test area.  A white car stops to allow pedestrians to cross the road. Pedestrians are then shown walking toward the car and passing it without incident. One person appears to be using a cell phone while waiting to cross.  There is no collision between any pedestrian and any vehicle.</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>gs://bucket-video-wts/val/20230922_29_CN18_T1/vehicle_view/20230922_29_CN18_T1_vehicle_view.mp4</td>\n",
              "      <td>Here's a description of the video based on your questions:The video shows a street intersection with pedestrians and cyclists crossing.  There is a traffic light present, but the level of adherence to the traffic signals by pedestrians and cyclists is not fully clear. The video is shot from a static point of view and does not show the street from all angles.There is no collision or accident shown in the video between pedestrians or cyclists and vehicles.  However, there is an incident involving a cyclist falling near the crosswalk.</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>gs://bucket-video-wts/val/20230929_41_CN36_T1/vehicle_view/20230929_41_CN36_T1_vehicle_view.mp4</td>\n",
              "      <td>Here are the answers based on the provided video:- The video shows a pedestrian crossing at a crosswalk.  A cyclist also crosses the road at the crosswalk.  Traffic signals are present to regulate the traffic and pedestrian flow. The video shows the traffic light turning red allowing pedestrians to cross safely.- No, there is no collision or accident shown in the video.</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>gs://bucket-video-wts/train/20230728_32_CN4_T1/vehicle_view/20230728_32_CN4_T1_vehicle_view.mp4</td>\n",
              "      <td>Here are the answers based on the provided video:- The video shows a car approaching a pedestrian crossing. Two pedestrians are waiting at the crossing, and the traffic light is red for the car. The car stops, allowing the pedestrians to cross safely.- No, there is no collision or accident between pedestrians and vehicles in the video.</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>gs://bucket-video-wts/train/20230922_27_CN2_T1/overhead_view/20230922_27_CN2_T1_192.168.0.17_1.mp4</td>\n",
              "      <td>Here's a description of the video concerning pedestrian safety and whether a collision occurred:The video shows a wide shot of a multi-lane intersection with pedestrian crosswalks.  Several pedestrians and a cyclist are using the crosswalks. A white car approaches the intersection while the pedestrians are crossing. The car slows down and safely passes the pedestrians and cyclist in the crosswalk. The traffic light is visible, and it appears to change from red to yellow during the video.No, there is no collision or accident (no contact or hit between pedestrians and vehicles) in the video.</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>gs://bucket-video-wts/train/20230728_40_SN31_T1/overhead_view/20230728_40_SN31_T1_Camera3_1.mp4</td>\n",
              "      <td>Here's a description of the video and answers to your questions:**Video Description:**The video shows a driving test area.  Several people are practicing driving maneuvers in cars and on bicycles. Pedestrians are also present in the area.  Some pedestrians walk near the vehicles, and at one point, a cyclist nearly collides with a car.**Questions:**- **Pedestrian Safety:** The video shows several instances where pedestrian safety is not prioritized. Pedestrians are walking near moving vehicles without clear separation or right-of-way. A cyclist nearly collides with a car because he has no safe zone to use.- **Collision/Accident:** No direct collision or accident between pedestrians and vehicles occurs in the video. However, a near miss happens between a cyclist and a car.</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>gs://bucket-video-wts/train/20230929_60_CN16_T1/vehicle_view/20230929_60_CN16_T1_vehicle_view.mp4</td>\n",
              "      <td>Here are the answers based on the provided video:- The video shows a car's rear view, looking out at a seemingly empty driving range or similar area.  There are no pedestrians visible in the driving range area, and no indication of pedestrian crossings or walkways. There is a fence separating the driving range and the road, suggesting a measure to protect pedestrians.- No, there is no collision or accident between pedestrians and vehicles shown in the video.</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>gs://bucket-video-wts/train/20230929_58_SN40_T1/overhead_view/20230929_58_SN40_T1_192.168.0.13_4.mp4</td>\n",
              "      <td>Here's a description of the video and answers to your questions:**Video Description:** The video shows a high-angle view of a road intersection with pedestrian crosswalks. Several pedestrians are crossing the road at different times. A white car approaches the intersection and stops to allow pedestrians to cross before continuing.**Pedestrian Safety:** The video shows a scenario where drivers yield to pedestrians in a crosswalk, and pedestrians appear to be aware of oncoming traffic.**Collision/Accident:** No, there is no collision or accident between pedestrians and vehicles in the video.</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bdac85e-a092-4311-8e51-3013e8701357')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7bdac85e-a092-4311-8e51-3013e8701357 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7bdac85e-a092-4311-8e51-3013e8701357');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d1589e40-2900-40fe-a62c-5adae092266b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d1589e40-2900-40fe-a62c-5adae092266b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d1589e40-2900-40fe-a62c-5adae092266b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reemplazamos los valores."
      ],
      "metadata": {
        "id": "CQNn5S4Hsjme"
      },
      "id": "CQNn5S4Hsjme"
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions.loc[df_gemini_captions.index[0], 'description'] = \"The video shows a car approaching a crosswalk at night. Several pedestrians are crossing the road. One pedestrian appears to briefly stop in front of the car, then continue walking. The car slows down but does not stop completely. The road is relatively dark with streetlights and there is a traffic signal visible.\"\n",
        "df_gemini_captions.loc[df_gemini_captions.index[0], 'collision/accident'] = \"There is no collision or accident between the pedestrians and the vehicle in the video.\""
      ],
      "metadata": {
        "id": "ovzQYawdYGWi"
      },
      "id": "ovzQYawdYGWi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions.loc[df_gemini_captions.index[6], 'description'] = \"The video shows a car driving at night on a road with minimal traffic. Pedestrians are seen crossing the road in front of the vehicle; however, the driver slows down and safely passes them without incident. A person briefly appears to be sitting on the car's hood.\"\n",
        "df_gemini_captions.loc[df_gemini_captions.index[6], 'collision/accident'] = \"There is no collision or accident between pedestrians and vehicles shown in the video.\""
      ],
      "metadata": {
        "id": "NLZkUHMssDz2"
      },
      "id": "NLZkUHMssDz2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions.loc[df_gemini_captions.index[11], 'description'] = \"The video shows a driving test area. Pedestrians are crossing a marked crosswalk. A car approaches the crosswalk and stops to allow the pedestrians to cross. The car then proceeds after pedestrians have crossed.\"\n",
        "df_gemini_captions.loc[df_gemini_captions.index[11], 'collision/accident'] = \"No collision or accident occurs between pedestrians and the vehicle.\""
      ],
      "metadata": {
        "id": "ZPaG7Te3tNqp"
      },
      "id": "ZPaG7Te3tNqp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions.loc[df_gemini_captions.index[23], 'description'] = \"The video shows a pedestrian crossing at a traffic intersection with pedestrian crosswalks and traffic signals. A white car approaches the crosswalk while pedestrians are crossing, but the car stops to allow them to proceed safely. The traffic light is red for the car.\"\n",
        "df_gemini_captions.loc[df_gemini_captions.index[23], 'collision/accident'] = \"No, there is no collision or accident between pedestrians and vehicles in the video.\""
      ],
      "metadata": {
        "id": "P0V5z9OctN74"
      },
      "id": "P0V5z9OctN74",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions.loc[df_gemini_captions.index[24], 'description'] = \"The video shows a pedestrian crossing with traffic signals. Pedestrians are seen crossing only when the traffic signal is green for pedestrians (and red for vehicles). There are clearly marked pedestrian crossings.\"\n",
        "df_gemini_captions.loc[df_gemini_captions.index[24], 'collision/accident'] = \"No, there is no collision or accident between pedestrians and vehicles in the video.\""
      ],
      "metadata": {
        "id": "cgalhV8xtOEY"
      },
      "id": "cgalhV8xtOEY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions.loc[df_gemini_captions.index[41], 'description'] = \"The video shows a driving test course. Pedestrians are crossing a marked crosswalk. A car approaches and stops to allow pedestrians to cross safely. The car then proceeds after the pedestrians have completely crossed.\"\n",
        "df_gemini_captions.loc[df_gemini_captions.index[41], 'collision/accident'] = \"No, there is no collision or accident between pedestrians and vehicles in the video.\""
      ],
      "metadata": {
        "id": "WRRgGYtLtOLB"
      },
      "id": "WRRgGYtLtOLB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions.loc[df_gemini_captions.index[68], 'description'] = \"The video shows a person on a skateboard crossing a road in a driving school area. A car is approaching the pedestrian, who stops before reaching the vehicle. The car stops, and the pedestrian appears to talk to the driver before continuing across the road.\"\n",
        "df_gemini_captions.loc[df_gemini_captions.index[68], 'collision/accident'] = \"No collision or accident occurs between the pedestrian and the vehicle.\""
      ],
      "metadata": {
        "id": "iBSg_HWvtOSF"
      },
      "id": "iBSg_HWvtOSF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions.loc[df_gemini_captions.index[72], 'description'] = \"The video shows a relatively empty intersection with pedestrians crossing a crosswalk. A car approaches the intersection and stops before the crosswalk while pedestrians are crossing. Pedestrians cross the crosswalk and the car waits until they have completed their crossing before proceeding through the intersection. The traffic light is red for vehicles while pedestrians are crossing.\"\n",
        "df_gemini_captions.loc[df_gemini_captions.index[72], 'collision/accident'] = \"No, there is no collision or accident between pedestrians and vehicles in the video.\""
      ],
      "metadata": {
        "id": "DQ6oC8motOZf"
      },
      "id": "DQ6oC8motOZf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions.loc[df_gemini_captions.index[73], 'description'] = \"The video shows a scene at what appears to be a driving school or test area. A white car stops to allow pedestrians to cross the road. Pedestrians are then shown walking toward the car and passing it without incident. One person appears to be using a cell phone while waiting to cross.\"\n",
        "df_gemini_captions.loc[df_gemini_captions.index[73], 'collision/accident'] = \"There is no collision between any pedestrian and any vehicle.\""
      ],
      "metadata": {
        "id": "kDkHcVlqtOgU"
      },
      "id": "kDkHcVlqtOgU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions.loc[df_gemini_captions.index[95], 'description'] = \"The video shows a street intersection with pedestrians and cyclists crossing. There is a traffic light present, but the level of adherence to the traffic signals by pedestrians and cyclists is not fully clear. The video is shot from a static point of view and does not show the street from all angles.\"\n",
        "df_gemini_captions.loc[df_gemini_captions.index[95], 'collision/accident'] = \"There is no collision or accident shown in the video between pedestrians or cyclists and vehicles. However, there is an incident involving a cyclist falling near the crosswalk.\""
      ],
      "metadata": {
        "id": "FgB4BX0xtOne"
      },
      "id": "FgB4BX0xtOne",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions.loc[df_gemini_captions.index[98], 'description'] = \"The video shows a pedestrian crossing at a crosswalk. A cyclist also crosses the road at the crosswalk. Traffic signals are present to regulate the traffic and pedestrian flow. The video shows the traffic light turning red allowing pedestrians to cross safely.\"\n",
        "df_gemini_captions.loc[df_gemini_captions.index[98], 'collision/accident'] = \"No, there is no collision or accident shown in the video.\""
      ],
      "metadata": {
        "id": "FLfOY8DbtOvs"
      },
      "id": "FLfOY8DbtOvs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions.loc[df_gemini_captions.index[103], 'description'] = \"The video shows a car approaching a pedestrian crossing. Two pedestrians are waiting at the crossing, and the traffic light is red for the car. The car stops, allowing the pedestrians to cross safely.\"\n",
        "df_gemini_captions.loc[df_gemini_captions.index[103], 'collision/accident'] = \"No, there is no collision or accident between pedestrians and vehicles in the video.\""
      ],
      "metadata": {
        "id": "juGQrN4UtO4m"
      },
      "id": "juGQrN4UtO4m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions.loc[df_gemini_captions.index[104], 'description'] = \"The video shows a wide shot of a multi-lane intersection with pedestrian crosswalks. Several pedestrians and a cyclist are using the crosswalks. A white car approaches the intersection while the pedestrians are crossing. The car slows down and safely passes the pedestrians and cyclist in the crosswalk. The traffic light is visible, and it appears to change from red to yellow during the video.\"\n",
        "df_gemini_captions.loc[df_gemini_captions.index[104], 'collision/accident'] = \"No, there is no collision or accident (no contact or hit between pedestrians and vehicles) in the video.\""
      ],
      "metadata": {
        "id": "kRGy_6JstPAx"
      },
      "id": "kRGy_6JstPAx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions.loc[df_gemini_captions.index[108], 'description'] = \"The video shows a driving test area. Several people are practicing driving maneuvers in cars and on bicycles. Pedestrians are also present in the area. Some pedestrians walk near the vehicles, and at one point, a cyclist nearly collides with a car. The video shows several instances where pedestrian safety is not prioritized. Pedestrians are walking near moving vehicles without clear separation or right-of-way. A cyclist nearly collides with a car because he has no safe zone to use.\"\n",
        "df_gemini_captions.loc[df_gemini_captions.index[108], 'collision/accident'] = \"No direct collision or accident between pedestrians and vehicles occurs in the video. However, a near miss happens between a cyclist and a car.\""
      ],
      "metadata": {
        "id": "axYM8mTytPJk"
      },
      "id": "axYM8mTytPJk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions.loc[df_gemini_captions.index[121], 'description'] = \"The video shows a car's rear view, looking out at a seemingly empty driving range or similar area. There are no pedestrians visible in the driving range area, and no indication of pedestrian crossings or walkways. There is a fence separating the driving range and the road, suggesting a measure to protect pedestrians.\"\n",
        "df_gemini_captions.loc[df_gemini_captions.index[121], 'collision/accident'] = \" No, there is no collision or accident between pedestrians and vehicles shown in the video.\""
      ],
      "metadata": {
        "id": "Ni9B0bT8tPah"
      },
      "id": "Ni9B0bT8tPah",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions.loc[df_gemini_captions.index[134], 'description'] = \"The video shows a high-angle view of a road intersection with pedestrian crosswalks. Several pedestrians are crossing the road at different times. A white car approaches the intersection and stops to allow pedestrians to cross before continuing. The video shows a scenario where drivers yield to pedestrians in a crosswalk, and pedestrians appear to be aware of oncoming traffic.\"\n",
        "df_gemini_captions.loc[df_gemini_captions.index[134], 'collision/accident'] = \"No, there is no collision or accident between pedestrians and vehicles in the video.\""
      ],
      "metadata": {
        "id": "9dAJLG2g1r28"
      },
      "id": "9dAJLG2g1r28",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions['class'] = df_gemini_captions['collision/accident'].apply(lambda x: 1 if 'yes' in x.lower() else 0)"
      ],
      "metadata": {
        "id": "PQl_xWrS1r5o"
      },
      "id": "PQl_xWrS1r5o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Datos de entrenamiento y prueba"
      ],
      "metadata": {
        "id": "uThzzJeavREX"
      },
      "id": "uThzzJeavREX"
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions = pd.read_csv('video_captions.csv')"
      ],
      "metadata": {
        "id": "m9a7lkv_fmzG",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730578921281,
          "user_tz": 360,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "m9a7lkv_fmzG",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_gemini_captions['caption'], df_gemini_captions['class'], test_size=0.2, random_state=7)"
      ],
      "metadata": {
        "id": "J_jmYlpk4TCO",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730578929669,
          "user_tz": 360,
          "elapsed": 636,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 10,
      "outputs": [],
      "id": "J_jmYlpk4TCO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ingenieria de caracteristicas y modelos**"
      ],
      "metadata": {
        "id": "MIi2BT5IfaKx"
      },
      "id": "MIi2BT5IfaKx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Regresion Logistica**"
      ],
      "metadata": {
        "id": "lRw5ejOZBg0R"
      },
      "id": "lRw5ejOZBg0R"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ingenieria de caracteristicas con POS TAGS"
      ],
      "metadata": {
        "id": "_PJvyDL65Qp6"
      },
      "id": "_PJvyDL65Qp6"
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHwRKDa4bok6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730578932882,
          "user_tz": 360,
          "elapsed": 532,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "764189a9-8a15-4729-d9f2-b8944858b8fe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "id": "nHwRKDa4bok6"
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tibki0unci2r",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730578933554,
          "user_tz": 360,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "8f1b7978-3c12-48ff-c542-5c3032a3218d"
      },
      "id": "tibki0unci2r",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tag = X_train.apply(add_pos_tags)\n",
        "X_test_tag = X_test.apply(add_pos_tags)"
      ],
      "metadata": {
        "id": "sDBol59tcPw7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730578937947,
          "user_tz": 360,
          "elapsed": 1405,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "sDBol59tcPw7",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "7BzGJXcj6-S_",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730578937947,
          "user_tz": 360,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "7BzGJXcj6-S_",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_vec = vectorizer.fit_transform(X_train_tag)\n",
        "X_test_vec = vectorizer.transform(X_test_tag)"
      ],
      "metadata": {
        "id": "EHP5lIoU7ECG",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730578937947,
          "user_tz": 360,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "EHP5lIoU7ECG",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ros = RandomOverSampler(random_state=7)"
      ],
      "metadata": {
        "id": "jf64aPFLBuPq",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730578938474,
          "user_tz": 360,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "jf64aPFLBuPq",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_vec_resampled, y_train_resampled = ros.fit_resample(X_train_vec, y_train)"
      ],
      "metadata": {
        "id": "bDUhx_eXBv9U",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730578939548,
          "user_tz": 360,
          "elapsed": 565,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "bDUhx_eXBv9U",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo con POS TAGS"
      ],
      "metadata": {
        "id": "dBpgre62ukeG"
      },
      "id": "dBpgre62ukeG"
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(X_train_vec_resampled, y_train_resampled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "_YJ-EFTU7U6t",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730578940334,
          "user_tz": 360,
          "elapsed": 4,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "3bed858e-7858-492d-d805-5381e5a80a04"
      },
      "id": "_YJ-EFTU7U6t",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_vec)"
      ],
      "metadata": {
        "id": "udvDPKC67uVR",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730578940962,
          "user_tz": 360,
          "elapsed": 1,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "udvDPKC67uVR",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "L4epYvBr71mi",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730578942259,
          "user_tz": 360,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "L4epYvBr71mi",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy: ', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51YxM0Zd77qR",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730578943376,
          "user_tz": 360,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "3521c626-a172-4076-d3a7-0007106e5eb2"
      },
      "id": "51YxM0Zd77qR",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Recall: ', recall)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B8KFTl979nU",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730578945003,
          "user_tz": 360,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "e80ec47d-927e-44ae-9ad0-5863f15ea72f"
      },
      "id": "2B8KFTl979nU",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ingenieria de caracteristicas con Features"
      ],
      "metadata": {
        "id": "HMDO-xtGZyg-"
      },
      "id": "HMDO-xtGZyg-"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizerZS = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21d847VbMcKJ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730578951372,
          "user_tz": 360,
          "elapsed": 1960,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "e91e0a10-4f85-4db9-c77f-f3551c142a74"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "id": "21d847VbMcKJ"
    },
    {
      "cell_type": "code",
      "source": [
        "modelZS = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KNxjnJEM4kT",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730578971453,
          "user_tz": 360,
          "elapsed": 2431,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "4383399d-e44b-47b4-ec22-10a2068f04cc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "id": "1KNxjnJEM4kT"
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions['features'] = df_gemini_captions['caption'].apply(extract_features)"
      ],
      "metadata": {
        "id": "WJTb-sVXLzsU",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579036630,
          "user_tz": 360,
          "elapsed": 54309,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 25,
      "outputs": [],
      "id": "WJTb-sVXLzsU"
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions_train = df_gemini_captions.sample(frac=0.8, random_state=7)\n",
        "df_gemini_captions_test = df_gemini_captions.drop(df_gemini_captions_train.index)"
      ],
      "metadata": {
        "id": "kzIqARqQPfhS",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579115559,
          "user_tz": 360,
          "elapsed": 267,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 28,
      "outputs": [],
      "id": "kzIqARqQPfhS"
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_features = df_gemini_captions_train['features'].tolist()\n",
        "y_train_features = df_gemini_captions_train['class'].tolist()"
      ],
      "metadata": {
        "id": "LbpTAIssQsml",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579118450,
          "user_tz": 360,
          "elapsed": 273,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 29,
      "outputs": [],
      "id": "LbpTAIssQsml"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo con Features"
      ],
      "metadata": {
        "id": "j8B-CHm1ZylJ"
      },
      "id": "j8B-CHm1ZylJ"
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = LogisticRegression()"
      ],
      "metadata": {
        "id": "gs_o8CbvOxKe",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579119942,
          "user_tz": 360,
          "elapsed": 320,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 30,
      "outputs": [],
      "id": "gs_o8CbvOxKe"
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.fit(X_train_features, y_train_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "qazzeWwnO2_S",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579133610,
          "user_tz": 360,
          "elapsed": 4,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "f83a5c05-048c-4bde-c233-13391358f7ce"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "id": "qazzeWwnO2_S"
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_features = df_gemini_captions_test['features'].tolist()\n",
        "y_test_features = df_gemini_captions_test['class'].tolist()"
      ],
      "metadata": {
        "id": "YYvb0BIjO9jF",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579150363,
          "user_tz": 360,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 33,
      "outputs": [],
      "id": "YYvb0BIjO9jF"
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_features = classifier.predict(X_test_features)"
      ],
      "metadata": {
        "id": "Q6-m6sC6Srfu",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579162320,
          "user_tz": 360,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 34,
      "outputs": [],
      "id": "Q6-m6sC6Srfu"
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test_features, y_pred_features)\n",
        "recall = recall_score(y_test_features, y_pred_features, zero_division=0.0)"
      ],
      "metadata": {
        "id": "eDfx3Ob8SxVP",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579453217,
          "user_tz": 360,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 38,
      "outputs": [],
      "id": "eDfx3Ob8SxVP"
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy: ', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS7l1aXTS82X",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579455928,
          "user_tz": 360,
          "elapsed": 445,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "6434388d-60ed-4d01-f627-0d02fee1ac8a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  1.0\n"
          ]
        }
      ],
      "id": "ZS7l1aXTS82X"
    },
    {
      "cell_type": "code",
      "source": [
        "print('Recall: ', recall)"
      ],
      "metadata": {
        "id": "sLusbVFQS-5n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579456904,
          "user_tz": 360,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "414c179c-9b83-4c6f-9fd8-c1bf1692e811"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall:  0.0\n"
          ]
        }
      ],
      "id": "sLusbVFQS-5n"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Red Neuronal Analisis de Sentimientos**"
      ],
      "metadata": {
        "id": "EeHtfaLkB0XD"
      },
      "id": "EeHtfaLkB0XD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ingeniria de caracteristicas"
      ],
      "metadata": {
        "id": "KMvxML_GuhN8"
      },
      "id": "KMvxML_GuhN8"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=10000)"
      ],
      "metadata": {
        "id": "0BSJT3gS-PKC",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579484682,
          "user_tz": 360,
          "elapsed": 266,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "0BSJT3gS-PKC",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(X_train)"
      ],
      "metadata": {
        "id": "zrHIbDNpvkYK",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579485725,
          "user_tz": 360,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "zrHIbDNpvkYK",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_token = tokenizer.texts_to_sequences(X_train)"
      ],
      "metadata": {
        "id": "YP9YnBfEvr57",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579487213,
          "user_tz": 360,
          "elapsed": 441,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "YP9YnBfEvr57",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_token = tokenizer.texts_to_sequences(X_test)"
      ],
      "metadata": {
        "id": "fig-T6L9v9mY",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579488610,
          "user_tz": 360,
          "elapsed": 450,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "fig-T6L9v9mY",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 256"
      ],
      "metadata": {
        "id": "WSk4SanewHAy",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579489550,
          "user_tz": 360,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "WSk4SanewHAy",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_token = pad_sequences(X_train_token, maxlen = max_length)"
      ],
      "metadata": {
        "id": "LW85TvMJxwCv",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579490561,
          "user_tz": 360,
          "elapsed": 1,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "LW85TvMJxwCv",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_token = pad_sequences(X_test_token, maxlen = max_length)"
      ],
      "metadata": {
        "id": "m7wjFhuEyEb8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579491226,
          "user_tz": 360,
          "elapsed": 1,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "m7wjFhuEyEb8",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo"
      ],
      "metadata": {
        "id": "KSrD2DgKyP4l"
      },
      "id": "KSrD2DgKyP4l"
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(10000, 128))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "_2qPt1VGyMvn",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579493673,
          "user_tz": 360,
          "elapsed": 227,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "_2qPt1VGyMvn",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', Recall()])"
      ],
      "metadata": {
        "id": "9k3HbYdAyYlT",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579494612,
          "user_tz": 360,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "9k3HbYdAyYlT",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ros = RandomOverSampler(random_state=7)"
      ],
      "metadata": {
        "id": "3oxbWChsDg5w",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579495798,
          "user_tz": 360,
          "elapsed": 1,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "3oxbWChsDg5w",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_token_resampled, y_train_resampled = ros.fit_resample(X_train_token, y_train)"
      ],
      "metadata": {
        "id": "dy5V32b1Edxw",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579496932,
          "user_tz": 360,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "dy5V32b1Edxw",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_token_resampled, y_train_resampled, epochs=1, batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNagiYP40QrB",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579501411,
          "user_tz": 360,
          "elapsed": 3351,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "848ef9e6-bb9f-4f43-ad65-3cabfebad85c"
      },
      "id": "WNagiYP40QrB",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 442ms/step - accuracy: 0.4914 - loss: 0.6797 - recall: 0.4436 - val_accuracy: 1.0000 - val_loss: 0.6816 - val_recall: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c4699244520>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, accuracy, recall = model.evaluate(X_test_token, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUeg7nKZ0389",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579509650,
          "user_tz": 360,
          "elapsed": 280,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "f4f39248-f726-4cff-c2da-87f28c8ab7b9"
      },
      "id": "GUeg7nKZ0389",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.9333 - loss: 0.5862 - recall: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy: ', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lL7GZ2oCHKp",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579510693,
          "user_tz": 360,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "392dd7fe-a77d-423d-e02d-fc32c3f5650d"
      },
      "id": "7lL7GZ2oCHKp",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9333333373069763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Recall: ', recall)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-maP3-uD1Enl",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579512125,
          "user_tz": 360,
          "elapsed": 266,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "b2931c7d-ce7e-4680-f93d-1e7225697f72"
      },
      "id": "-maP3-uD1Enl",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **fastText**"
      ],
      "metadata": {
        "id": "BTEp_2C1CNZO"
      },
      "id": "BTEp_2C1CNZO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo"
      ],
      "metadata": {
        "id": "EL2AGHbcC8eK"
      },
      "id": "EL2AGHbcC8eK"
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train.txt', 'w') as f:\n",
        "  for text, label in zip(X_train, y_train):\n",
        "    f.write(f\"__label__{label} {text}\\n\")\n",
        "\n",
        "with open('test.txt', 'w') as f:\n",
        "  for text, label in zip(X_test, y_test):\n",
        "    f.write(f\"__label__{label} {text}\\n\")"
      ],
      "metadata": {
        "id": "Orj8sQIrQYHq",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579521216,
          "user_tz": 360,
          "elapsed": 257,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "Orj8sQIrQYHq",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = fasttext.train_supervised(input='train.txt', epoch=25, lr=1.0, wordNgrams=2, verbose=2, minCount=1)"
      ],
      "metadata": {
        "id": "IWWPwMqVRZ0e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579522650,
          "user_tz": 360,
          "elapsed": 575,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "IWWPwMqVRZ0e",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_result = model.test('test.txt')"
      ],
      "metadata": {
        "id": "XsQuOtWvRZ3X",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579523758,
          "user_tz": 360,
          "elapsed": 1,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "XsQuOtWvRZ3X",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_result[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2eUnGvJRZ6q",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579524082,
          "user_tz": 360,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "8f4aef65-9816-401f-c404-316ca2112b53"
      },
      "id": "J2eUnGvJRZ6q",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Modelo final**"
      ],
      "metadata": {
        "id": "lTXQtLZwf8nj"
      },
      "id": "lTXQtLZwf8nj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como modelo final se eligio una clasificacion con Zero-Shot, tuvo un performance aceptable con las metricas elegidas: Accuracy y Recall. Aunque el presente Notebook lo consideramos un primer paso de una analisis que se deberia llevar de manera mas profunda en el futuro."
      ],
      "metadata": {
        "id": "hc-nxyOAge-V"
      },
      "id": "hc-nxyOAge-V"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Zero-shot classification**"
      ],
      "metadata": {
        "id": "Y75WYqQmDK1U"
      },
      "id": "Y75WYqQmDK1U"
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    classifier = pipeline('zero-shot-classification', model = 'facebook/bart-large-mnli', device=\"cuda\")\n",
        "else:\n",
        "    classifier = pipeline('zero-shot-classification', model = 'facebook/bart-large-mnli')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRrb-3TZl0e9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579539560,
          "user_tz": 360,
          "elapsed": 1548,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "518f9f52-4dba-4ec1-848f-e6fda79062d2"
      },
      "id": "MRrb-3TZl0e9",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "candidate_collision_labels = ['a collision', 'accident', 'hitting']\n",
        "candidate_no_collision_labels = ['no collision', 'no accident']"
      ],
      "metadata": {
        "id": "d0FJjXxruJDn",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579542869,
          "user_tz": 360,
          "elapsed": 272,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "d0FJjXxruJDn",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gemini_captions['prediction'] = df_gemini_captions.apply(lambda x: classify_text(x['caption'], candidate_collision_labels, candidate_no_collision_labels), axis=1)"
      ],
      "metadata": {
        "id": "b30WnNzrw3Ss",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730579961706,
          "user_tz": 360,
          "elapsed": 323628,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "b30WnNzrw3Ss",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(df_gemini_captions['class'], df_gemini_captions['prediction'])"
      ],
      "metadata": {
        "id": "o0Xae8W_yOZX",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730580344852,
          "user_tz": 360,
          "elapsed": 279,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "o0Xae8W_yOZX",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recall = recall_score(df_gemini_captions['class'], df_gemini_captions['prediction'])"
      ],
      "metadata": {
        "id": "5BxBdJji3umN",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730580325419,
          "user_tz": 360,
          "elapsed": 330,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "5BxBdJji3umN",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy: ', accuracy)"
      ],
      "metadata": {
        "id": "foOpGZ6VLC_V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730580362037,
          "user_tz": 360,
          "elapsed": 287,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "575181a9-756b-47cb-9cb7-0ee08b41b391"
      },
      "id": "foOpGZ6VLC_V",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9866666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Recall: ', recall)"
      ],
      "metadata": {
        "id": "vrNfUwHHK3aw",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730580376491,
          "user_tz": 360,
          "elapsed": 283,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e130b8cf-57f1-4647-9f99-0558ab7dcf42"
      },
      "id": "vrNfUwHHK3aw",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall:  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conclusiones**"
      ],
      "metadata": {
        "id": "gwn8O4sJmWC7"
      },
      "id": "gwn8O4sJmWC7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el presente analisis se utilizaron como datos las transcripciones generadas con Gemini de 150 videos de la base WTS, en las que se le solicito a Gemini dar una descripcion del video asi como una clasificacion de si habia alguna colision o accidente, la clasificacion de Gemini se considero como dada ante la ejecucion de los modelos seleccionados. Cabe señalar que de los 150 videos Gemini solo clasifico 4 en los que habia una colision o accidente, los cuales fueron validados. Se probaron los modelos: Regresion Logistica, Red Neuronal, fastText y Zero-Shot. En los dos primeros casos se busco aplicar algunas tecnicas de feature engineering como tokenizaciones y POS TAG. Dado que se tenia una clase desbalanceada el Zero-Shot presento el mejor desempeño. Consideramos que el prsente analisis es un primer paso para seguir explorando los conflictos viales."
      ],
      "metadata": {
        "id": "PVCCKkEtmZXh"
      },
      "id": "PVCCKkEtmZXh"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jaLj3rP2rixp"
      },
      "id": "jaLj3rP2rixp",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "Avance5Equipo13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}