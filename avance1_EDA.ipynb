{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "592fbfb7-bb1c-4252-af58-3db5fe465c77",
   "metadata": {},
   "source": [
    "# **Avance 1. Análisis exporatorio de datos**\n",
    "\n",
    "---\n",
    "\n",
    "Profa. Dra. Grettel Barceló Alonso \n",
    "\n",
    "Prof. Dr. Luis Eduardo Falcón Morales \n",
    "\n",
    "Profa. Verónica Sandra Guzmán de Valle \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Estudiantes:**\n",
    "\n",
    "\n",
    "Marcela Alejandra Rosales Jiménez – A01032022\n",
    "\n",
    "José Antonio Mendoza Castro – A01794067\n",
    "\n",
    "\n",
    "29 de septiembre de 2024\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e5979b-2d9a-42f3-a485-5b925a3f8663",
   "metadata": {},
   "source": [
    "## WTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd6767a-435f-44c7-b6cf-4cbd3f48762f",
   "metadata": {},
   "source": [
    "### **Videos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825b0be6-6deb-46bf-ba59-9f612ad034df",
   "metadata": {},
   "source": [
    "Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56f6ca92-2f9a-4eea-905c-1f40a44dfa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7654beb-02ca-4fe9-abfd-a6befbcaa327",
   "metadata": {},
   "source": [
    "Visualizar cuantos archivos en el directorio `wts_dataset_zip`. Antes de correr el siguiente codigo se verifico que ya se hubieran extraido los 4 archivos zip que estaban dentro del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c69e7705-bc48-4aad-9793-5f52dc32f7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = f\"dataset/wts_dataset_zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92b01fef-c2a2-4aa3-8925-e2527167a2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de archivos en total = 14126\n",
      " - Extension .csv tiene 1\n",
      " - Extension .zip tiene 4\n",
      " - Extension  tiene 1\n",
      " - Extension .DS_Store tiene 1\n",
      " - Extension .json tiene 9907\n",
      " - Extension .mp4 tiene 4212\n"
     ]
    }
   ],
   "source": [
    "def get_all_files(files_path):\n",
    "    files_path = pathlib.Path(files_path)\n",
    "    listed_elements = list(files_path.rglob(\"*\"))                           \n",
    "    listed_files = [e for e in listed_elements if not e.is_dir()]\n",
    "    return listed_files\n",
    "\n",
    "def get_listed_files_with_types(listed_files):\n",
    "  files_types = {}\n",
    "  for ff in listed_files:\n",
    "    ext = ff.suffix\n",
    "    if not files_types.get(ext):\n",
    "      files_types[ext] = []\n",
    "    files_types[ext].append(str(ff))\n",
    "  return files_types\n",
    "\n",
    "\n",
    "\n",
    "listed_files = get_all_files(f\"{dataset_path}\")\n",
    "print(f\"Cantidad de archivos en total = {len(listed_files)}\")\n",
    "\n",
    "\n",
    "files_by_ext = get_listed_files_with_types(listed_files)\n",
    "\n",
    "for k, v in files_by_ext.items():\n",
    "    print(f\" - Extension {k} tiene {len(v)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9727e0-752f-4888-9f63-1d93221906ce",
   "metadata": {},
   "source": [
    "Podemos ver que dentro de el zip del dataset hay 4,212 videos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0c9b23-c699-4344-b9a1-e2e694157128",
   "metadata": {},
   "source": [
    "Visualmente se evaluan los videos y se decide lo siguiente\n",
    "- No se utilizarán los videos que estan dentro de `wts_dataset_zip/external` ya que son grabaciones desde la perspectiva del asiento delantero de un carro.\n",
    "- No se utilizarán los videos que estén dentro de una carpeta llamada `vehicle_view` por el mismo motivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f4050f2a-a257-4123-b5d4-86880d4fda16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de archivos a utilizar = 600\n",
      " - train tiene 403\n",
      " - val tiene 197\n"
     ]
    }
   ],
   "source": [
    "files_overhead_view = []\n",
    "files_overhead_view_by_type = {\n",
    "    'train': [],\n",
    "    'val': [],\n",
    "}\n",
    "\n",
    "for mp4 in files_by_ext['.mp4']:\n",
    "    if not f\"{dataset_path}/external\" in mp4 and not \"vehicle_view\" in  mp4:\n",
    "        files_overhead_view.append(mp4)\n",
    "        if \"videos/train\" in mp4:\n",
    "            files_overhead_view_by_type['train'].append(mp4)\n",
    "        elif \"videos/val\" in mp4:\n",
    "            files_overhead_view_by_type['val'].append(mp4)\n",
    "        else:\n",
    "            print(f\"W: No train ni val. Que es? {mp4}\")\n",
    "            \n",
    "\n",
    "print(f\"Cantidad de archivos a utilizar = {len(files_overhead_view)}\")\n",
    "for k, v in files_overhead_view_by_type.items():\n",
    "    print(f\" - {k} tiene {len(v)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2541d83a-9775-49c5-b359-c91318e7e1ef",
   "metadata": {},
   "source": [
    "Podemos concluir que para los objetivos de nuestro proyecto tenemos 600 videos mp4, de los cuales el dataset de WTS sugiere usar 403 en videos de entrenamiento y 197 en videos de validación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d727993a-64fd-421b-8a69-e336ca883cb1",
   "metadata": {},
   "source": [
    "### **Anotaciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0cf3ffb6-fb99-4f70-b188-82a80b27f3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset/wts_dataset_zip/videos/train/20231006_15_CN28_T1/overhead_view/20231006_15_CN28_T1_192.168.0.13_4.mp4'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_overhead_view_by_type['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c69f6d85-46b7-43a1-8755-b3980daaf284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": 1720,\n",
      "    \"overhead_videos\": [\n",
      "        \"20231006_15_CN28_T1_192.168.0.11_1.mp4\",\n",
      "        \"20231006_15_CN28_T1_192.168.0.12_3.mp4\",\n",
      "        \"20231006_15_CN28_T1_192.168.0.13_4.mp4\",\n",
      "        \"20231006_15_CN28_T1_192.168.0.28_2.mp4\"\n",
      "    ],\n",
      "    \"event_phase\": [\n",
      "        {\n",
      "            \"labels\": [\n",
      "                \"4\"\n",
      "            ],\n",
      "            \"caption_pedestrian\": \"The pedestrian is a male in his 30s with a height of 170 cm. He is wearing a black T-shirt and black slacks. It is a clear and bright day with the road surface being dry and level. The pedestrian is walking in front of the vehicle, in the opposite direction, and on the left side. He is relatively close to the vehicle. The pedestrian notices the vehicle approaching and traveling on a residential road with two-way traffic. The pedestrian is slowly walking in a car lane. There is no sidewalk on either side, and the roadside strip is also absent. The pedestrian's general action is a collision. Overall, the pedestrian is in an environment with typical traffic volume, on a residential road with asphalt. The pedestrian's movements and the surrounding conditions contribute to a potentially dangerous situation.\",\n",
      "            \"caption_vehicle\": \"The vehicle was positioned on the left side of a pedestrian, at a close distance. The pedestrian was clearly visible within the vehicle's field of view. Unexpectedly, the vehicle collided with the pedestrian, causing both parties to come to a halt. The vehicle was stationary at the time of the collision, with a speed of 0 km/h. Meanwhile, in the surrounding environment, the pedestrian was described as a male in his 30s, of approximately 170 cm in height. He was wearing a black T-shirt for his upper body and black slacks for his lower body. The weather conditions were clear, with bright brightness. The road surface was dry and level, consisting of asphalt. The road was a residential road with two-way traffic and no sidewalks on both sides. Additionally, there were no roadside strips. The events occurred in the usual traffic volume of the area.\",\n",
      "            \"start_time\": \"30.803\",\n",
      "            \"end_time\": \"33.681\"\n",
      "        },\n",
      "        {\n",
      "            \"labels\": [\n",
      "                \"3\"\n",
      "            ],\n",
      "            \"caption_pedestrian\": \"The pedestrian, a male in his 30s dressed in a black T-shirt and slacks, was spotted diagonally to the left in front of the vehicle on a residential road. His body was oriented in the opposite direction of the vehicle, and his line of sight was focused ahead in the direction of travel. With clear and bright weather conditions, the road surface was dry and level, providing optimal visibility and ease of movement. Despite the usual traffic volume on the two-way road, the pedestrian was closely watching the vehicle as he slowly proceeded straight ahead, traveling within the car lane. Both the pedestrian's appearance and actions indicated a cautious and aware demeanor. The surrounding environment, characterized by asphalt road and no sidewalks on both sides, contributed to the pedestrian's position and behavior.\",\n",
      "            \"caption_vehicle\": \"The vehicle is positioned diagonally to the left in front of the pedestrian, who is far away. The pedestrian is in the vehicle's field of view and is visible to the driver. The vehicle is going straight ahead at a speed of 20 km/h. The driver is aware of the pedestrian's presence and is maintaining a safe distance. The vehicle is in a clear and bright environment with dry and level road surface conditions. The driver is driving on a two-way residential road with usual traffic volume. The road is made of asphalt and does not have sidewalks on both sides or roadside strips. The driver is a male in his 30s of height 170 cm. He is wearing a black t-shirt and black slacks. No additional information is available about the driver's emotions or intentions.\",\n",
      "            \"start_time\": \"23.756\",\n",
      "            \"end_time\": \"30.814\"\n",
      "        },\n",
      "        {\n",
      "            \"labels\": [\n",
      "                \"2\"\n",
      "            ],\n",
      "            \"caption_pedestrian\": \"The pedestrian in this event is a male in his 30s with a height of approximately 170 cm. He is wearing a black T-shirt and black slacks. The weather is clear, with bright brightness, and the road surface is dry and level asphalt. The event takes place on a residential road with two-way traffic and a usual traffic volume. There is no sidewalk on both sides of the road, nor a roadside strip. The pedestrian's body orientation is opposite to that of the vehicle, and he is diagonally positioned to the left in front of the vehicle. The pedestrian's line of sight is in front, aligned with the direction of travel. He is closely watching and notices the vehicle. The pedestrian's general action is going straight ahead, and he is traveling in a car lane. He is moving slowly.\",\n",
      "            \"caption_vehicle\": \"The vehicle is positioned diagonally to the left in front of the pedestrian, and it is far from the pedestrian. The pedestrian is visible within the vehicle's field of view. The vehicle is going straight ahead at a speed of 10 km/h. The driver of the vehicle observes a male pedestrian in his 30s with a height of 170 cm. The pedestrian is wearing a black T-shirt on the upper body and black slacks on the lower body. The weather is clear and the brightness is bright. The road surface conditions are dry and flat, with asphalt as the road surface type. The traffic volume is usual on the residential road, which has two-way traffic. There are no sidewalks on both sides, and there is no roadside strip on both sides.\",\n",
      "            \"start_time\": \"22.761\",\n",
      "            \"end_time\": \"23.759\"\n",
      "        },\n",
      "        {\n",
      "            \"labels\": [\n",
      "                \"1\"\n",
      "            ],\n",
      "            \"caption_pedestrian\": \"The pedestrian, a male in his 30s, was spotted diagonally to the left and in front of the vehicle, with his body facing the opposite direction. He appeared far from the vehicle and had a clear line of sight in front, closely watching his surroundings. The pedestrian was dressed in a black T-shirt and black slacks, standing at a height of 170 cm. The weather was clear and bright, with dry and level asphalt on the residential road. The traffic volume was normal, in a two-way traffic lane, without sidewalks or roadside strips on both sides. Moving slowly, the pedestrian was seen going straight ahead. However, it was observed that the pedestrian was traveling in a car lane, which might not be the usual scenario for pedestrians. Overall, the event depicted a cautious pedestrian, fully aware of his surroundings and adhering to proper orientation and direction of travel.\",\n",
      "            \"caption_vehicle\": \"The vehicle is positioned diagonally to the left in front of the pedestrian. It is far away from the pedestrian. From the vehicle's field of view, the pedestrian is visible. The vehicle is currently going straight ahead at a speed of 10 km/h. The environment conditions surrounding the vehicle consist of a male pedestrian in his 30s with a height of 170 cm. He is wearing a black T-shirt on his upper body and black slacks on his lower body. The weather is clear and bright, with dry road surface conditions. The road is level and made of asphalt. The traffic volume is usual on this residential road, which consists of two-way traffic. There is no sidewalk on both sides and no roadside strip present. Based on this information alone, it is apparent that the vehicle is interacting with the pedestrian in these specific circumstances.\",\n",
      "            \"start_time\": \"21.772\",\n",
      "            \"end_time\": \"22.771\"\n",
      "        },\n",
      "        {\n",
      "            \"labels\": [\n",
      "                \"0\"\n",
      "            ],\n",
      "            \"caption_pedestrian\": \"The pedestrian, a man in his 30s, stood still on a residential road illuminated by bright sunlight. Wearing a black T-shirt and slacks, he had a clear line of sight ahead in the direction of travel. Standing diagonally to the left and far in front of the vehicle, his body faced the opposite direction to the car. With a height of 170 cm, he closely watched the surroundings while waiting. The road surface was dry and level, typical for usual traffic on a two-way street. Both the pedestrian and the vehicle shared the road, as there were no sidewalks or roadside strips on either side. The environment conditions indicated a pleasant, clear weather with asphalt road surface. Despite the usual traffic volume, the pedestrian confidently maintained his position, attentively observing his surroundings.\",\n",
      "            \"caption_vehicle\": \"The vehicle was positioned diagonally to the left in front of the pedestrian, appearing far away from them. From the vehicle's field of view, the pedestrian was visible. The vehicle had just started moving and was traveling at a speed of 5 km/h. Meanwhile, the environment conditions revealed that the pedestrian was a male in his 30s, standing at a height of 170 cm. He was wearing a black T-shirt on the upper body and black slacks on the lower body. The weather was clear, and the brightness of the surroundings was bright. The road surface conditions were dry and level, with asphalt as the surface type. The traffic volume was usual on the residential road, which had two-way traffic and not both sides had a sidewalk or roadside strip.\",\n",
      "            \"start_time\": \"20.763\",\n",
      "            \"end_time\": \"21.767\"\n",
      "        }\n",
      "    ]\n",
      "}"
     ]
    }
   ],
   "source": [
    "! cat dataset/wts_dataset_zip/annotations/caption/train/20231006_15_CN28_T1/overhead_view/20231006_15_CN28_T1_caption.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f2997e2c-9f29-41b1-af0b-1966431e8ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset', 'wts_dataset_zip', 'videos', 'train', '20231006_15_CN28_T1', 'overhead_view', '20231006_15_CN28_T1_192.168.0.13_4.mp4']\n"
     ]
    }
   ],
   "source": [
    "filepath = files_overhead_view_by_type['train'][0]\n",
    "\n",
    "tokens = filepath.split('/')\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ac4d2705-0366-444e-bff4-8bb61a705e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset/wts_dataset_zip/annotations/caption/'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{dataset_path}/annotations/caption/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "82c83089-f0e7-4a1a-ba00-ffc8b3f9fe07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20231006_15_CN28_T1_192.168.0.13_4.mp4'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_vehicle_view_by_type['train'][0].split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787a5335-d84d-4a0f-95ba-e5f7dd19b4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
