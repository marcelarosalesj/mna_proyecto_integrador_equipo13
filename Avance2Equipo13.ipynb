{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "FVsZHkiXXsgh",
      "metadata": {
        "id": "FVsZHkiXXsgh"
      },
      "source": [
        "\n",
        "# **Proyecto Integrador - Avance 2.Ingenieria de caracteristicas**\n",
        "## **Tecnologico de Monterrey**\n",
        "------------------------------------------------------------------\n",
        "### Profa. Dra. Grettel Barceló Alonso\n",
        "\n",
        "### Prof. Dr. Luis Eduardo Falcón Morales\n",
        "\n",
        "### Profa. Verónica Sandra Guzmán de Valle\n",
        "------------------------------------------------------------------\n",
        "### Marcela Alejandra Rosales Jiménez - A01032022\n",
        "### José Antonio Mendoza Castro - A01794067\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sGbTE_dYepfD",
      "metadata": {
        "id": "sGbTE_dYepfD"
      },
      "source": [
        "### Instalacion de librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A52QrO5Ay1FI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A52QrO5Ay1FI",
        "outputId": "9e08fe6a-8872-4be8-c1a9-8afc620efac5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython) (71.0.4)\n",
            "Collecting jedi>=0.16 (from ipython)\n",
            "  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.13)\n",
            "Using cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.19.1\n"
          ]
        }
      ],
      "source": [
        "pip install ipython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ZXFeNNPKlvCC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXFeNNPKlvCC",
        "outputId": "eab37945-911d-463f-b5ed-be01539928bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting get-video-properties\n",
            "  Downloading get_video_properties-0.1.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading get_video_properties-0.1.1-py3-none-any.whl (45.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: get-video-properties\n",
            "Successfully installed get-video-properties-0.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -U get-video-properties"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09GTd9igewGW",
      "metadata": {
        "id": "09GTd9igewGW"
      },
      "source": [
        "### Carpeta actual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "yNf2iDDpXrOo",
      "metadata": {
        "id": "yNf2iDDpXrOo"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "BqWy2yZfLEA8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BqWy2yZfLEA8",
        "outputId": "e01990ba-0ff5-4f60-f030-fe5ef73f2693"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QA0bZK2_e1L7",
      "metadata": {
        "id": "QA0bZK2_e1L7"
      },
      "source": [
        "### Librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "EI1tSNMxPL74",
      "metadata": {
        "id": "EI1tSNMxPL74"
      },
      "outputs": [],
      "source": [
        "from google.cloud import storage\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "Y2yEhJbSScCi",
      "metadata": {
        "id": "Y2yEhJbSScCi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "from IPython.display import HTML\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import random\n",
        "import re\n",
        "import json\n",
        "import io\n",
        "import pathlib\n",
        "from base64 import b64encode\n",
        "from videoprops import get_video_properties"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "rTcvLsZj53BE"
      },
      "id": "rTcvLsZj53BE",
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1gMFBjRKJaLD",
      "metadata": {
        "id": "1gMFBjRKJaLD"
      },
      "source": [
        "### **Recoleccion de datos**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dzS40jhbe4nS",
      "metadata": {
        "id": "dzS40jhbe4nS"
      },
      "source": [
        "### Cuenta de servicio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "m_3dzCsoe9lt",
      "metadata": {
        "id": "m_3dzCsoe9lt"
      },
      "outputs": [],
      "source": [
        "credentials = 'project-team-13-8b8c41c85749.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "i9F2KLTPPyqw",
      "metadata": {
        "id": "i9F2KLTPPyqw"
      },
      "outputs": [],
      "source": [
        "client = storage.Client.from_service_account_json(credentials)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yy4sgda_fGPI",
      "metadata": {
        "id": "yy4sgda_fGPI"
      },
      "source": [
        "### Bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "l_kbVm9ufhBS",
      "metadata": {
        "id": "l_kbVm9ufhBS"
      },
      "outputs": [],
      "source": [
        "bucket_name = 'bucket-video-wts'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "UxNe9z9dPzxq",
      "metadata": {
        "id": "UxNe9z9dPzxq"
      },
      "outputs": [],
      "source": [
        "bucket = client.get_bucket(bucket_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jpDPhbpUfOdK",
      "metadata": {
        "id": "jpDPhbpUfOdK"
      },
      "source": [
        "### Lectura de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "elN7H2gkxrYd",
      "metadata": {
        "id": "elN7H2gkxrYd"
      },
      "outputs": [],
      "source": [
        "def make_folder(folder_name):\n",
        "  \"\"\"\n",
        "  Funcion que crea una carpeta en el directorio actual.\n",
        "  \"\"\"\n",
        "  folder_path = os.path.join('/content/', folder_name)\n",
        "  os.makedirs(folder_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "XUW7N8leAnwb",
      "metadata": {
        "id": "XUW7N8leAnwb"
      },
      "outputs": [],
      "source": [
        "folder_ds = 'dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "GhqXzDg_AffG",
      "metadata": {
        "id": "GhqXzDg_AffG"
      },
      "outputs": [],
      "source": [
        "make_folder(folder_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "iPaOZwIuBnFJ",
      "metadata": {
        "id": "iPaOZwIuBnFJ"
      },
      "outputs": [],
      "source": [
        "list_folder = ['dataset/train/', 'dataset/val/', 'dataset/annotations/']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "-UrpPHrXxDG0",
      "metadata": {
        "id": "-UrpPHrXxDG0"
      },
      "outputs": [],
      "source": [
        "for folder in list_folder:\n",
        "  make_folder(folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "UkrT0wBkCgyg",
      "metadata": {
        "id": "UkrT0wBkCgyg"
      },
      "outputs": [],
      "source": [
        "list_path = ['train/', 'val/', 'annotations/']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "BwqBCxHMS6_C",
      "metadata": {
        "id": "BwqBCxHMS6_C"
      },
      "outputs": [],
      "source": [
        "for path in list_path:\n",
        "  blobs = [blob.name for blob in bucket.list_blobs(prefix=path)]\n",
        "  df_blobs = pd.DataFrame(blobs, columns=['file'])\n",
        "  df_blobs['check'] = df_blobs['file'].apply(lambda x: 1 if 'content' in x else 0)\n",
        "  df_blobs['lenght'] = df_blobs['file'].apply(lambda x: len(x))\n",
        "  for blob in blobs:\n",
        "    if len(blob) < 24:\n",
        "      pass\n",
        "    else:\n",
        "      blob_tmp = bucket.blob(blob)\n",
        "      blob_tmp.download_to_filename('/content/dataset/' + path + blob.split('/')[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HRQP2oawaCRp",
      "metadata": {
        "id": "HRQP2oawaCRp"
      },
      "source": [
        "### **Funciones**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "id": "VrIdeRc0c8tc",
      "metadata": {
        "id": "VrIdeRc0c8tc"
      },
      "outputs": [],
      "source": [
        "def get_all_files(files_path):\n",
        "  \"\"\"\n",
        "  Funcion que obtiene una lista de todos los archivos de un directorio.\n",
        "  \"\"\"\n",
        "  files_path = pathlib.Path(files_path)\n",
        "  listed_elements = list(files_path.rglob(\"*\"))\n",
        "  listed_files = [e for e in listed_elements if not e.is_dir()]\n",
        "\n",
        "  return listed_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "id": "0oGtf58Zc9rj",
      "metadata": {
        "id": "0oGtf58Zc9rj"
      },
      "outputs": [],
      "source": [
        "def get_listed_files_with_types(listed_files):\n",
        "  \"\"\"\n",
        "  Funcion que obtiene un diccionario con los tipos de archivos y la lista de archivos que pertenecen a ese tipo.\n",
        "  \"\"\"\n",
        "  files_types = {}\n",
        "  for ff in listed_files:\n",
        "    ext = ff.suffix\n",
        "    if not files_types.get(ext):\n",
        "      files_types[ext] = []\n",
        "    files_types[ext].append(str(ff))\n",
        "  return files_types"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cap_dataframe(overhead_view_list):\n",
        "  \"\"\"\n",
        "  Funcion que obtiene un dataframe con la informacion de los videos.\n",
        "  \"\"\"\n",
        "  overhead_view_num_frames = {}\n",
        "\n",
        "  for ff in overhead_view_list:\n",
        "      cap = cv2.VideoCapture(ff)\n",
        "      overhead_view_num_frames[ff] = [int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)), int(cap.get(cv2.CAP_PROP_FPS))]\n",
        "\n",
        "  df_tmp = pd.DataFrame.from_dict(overhead_view_num_frames, orient='index', columns=['num_frames', 'frame_width', 'frame_height', 'fps'])\n",
        "  df_tmp.reset_index(inplace=True)\n",
        "  df_tmp.rename(columns={'index': 'video_path'}, inplace=True)\n",
        "\n",
        "  return df_tmp"
      ],
      "metadata": {
        "id": "1VPFp5h_eh4W"
      },
      "id": "1VPFp5h_eh4W",
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "id": "TcdIuMq2SrXd",
      "metadata": {
        "id": "TcdIuMq2SrXd"
      },
      "outputs": [],
      "source": [
        "def get_radom_file(file_list):\n",
        "  \"\"\"\n",
        "  Funcion que obtiene un archivo aleatorio de un directorio.\n",
        "  \"\"\"\n",
        "  if file_list:\n",
        "    return random.choice(file_list)\n",
        "  else:\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "id": "mjUL2cE_aHBl",
      "metadata": {
        "id": "mjUL2cE_aHBl"
      },
      "outputs": [],
      "source": [
        "def play_video(video_path):\n",
        "\n",
        "  \"\"\"\n",
        "  Funcion que ejecuta un video desde un folder.\n",
        "  \"\"\"\n",
        "\n",
        "  video = open(video_path, 'rb').read()\n",
        "  video_data_url = 'data:video/mp4;base64,' + b64encode(video).decode()\n",
        "\n",
        "  print('Video Name: ', video_path)\n",
        "\n",
        "  return HTML(f\"\"\"\n",
        "  <video width=\"640\" height=\"480\" controls>\n",
        "    <source src=\"{video_data_url}\" type=\"video/mp4\">\n",
        "  </video>\n",
        "  \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "id": "oTXJIFHucwfg",
      "metadata": {
        "id": "oTXJIFHucwfg"
      },
      "outputs": [],
      "source": [
        "def get_annotation_path(video_path):\n",
        "  \"\"\"\n",
        "  Funcion que obtiene la ruta correspondiente de una anotacion.\n",
        "  \"\"\"\n",
        "  annotation_path = re.search('.*T[0-9](?=_)', video_path).group(0).replace('train', 'annotations') + '_caption.json'\n",
        "  return annotation_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "id": "5rpdhjc8G4zb",
      "metadata": {
        "id": "5rpdhjc8G4zb"
      },
      "outputs": [],
      "source": [
        "def get_annotation(video_path):\n",
        "  \"\"\"\n",
        "  Funcion que obtiene la anotacion correspondiente de un video.\n",
        "  \"\"\"\n",
        "  with open(get_annotation_path(video_path), 'r') as f:\n",
        "    data = json.load(f)\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "id": "yNfBKVeWd925",
      "metadata": {
        "id": "yNfBKVeWd925"
      },
      "outputs": [],
      "source": [
        "def get_video_duration_in_seconds(video_path):\n",
        "  \"\"\"\n",
        "  Funcion que devuelve la duracion en segundos de un video.\n",
        "  \"\"\"\n",
        "\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "  totalNoFrames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "  durationInSeconds = totalNoFrames // fps\n",
        "\n",
        "  return 'Duration in seconds: ' +  str(durationInSeconds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_characteristics(df_tmp):\n",
        "  \"\"\"\n",
        "  Funcion que obtiene las caracteristicas generales de los videos.\n",
        "  \"\"\"\n",
        "\n",
        "  general_characteristics = {}\n",
        "\n",
        "  list_seconds = []\n",
        "  list_width = []\n",
        "  list_height = []\n",
        "  list_frames = []\n",
        "  list_fps = []\n",
        "\n",
        "  for i, row in df_tmp.iterrows():\n",
        "    width = row['frame_width']\n",
        "    height = row['frame_height']\n",
        "    frame = row['num_frames']\n",
        "    fps = row['fps']\n",
        "    durationInSeconds = row['num_frames'] / row['fps']\n",
        "    list_width.append(width)\n",
        "    list_height.append(height)\n",
        "    list_frames.append(frame)\n",
        "    list_fps.append(fps)\n",
        "    list_seconds.append(durationInSeconds)\n",
        "\n",
        "  general_characteristics['width_mean'] = sum(list_width) / len(list_width)\n",
        "  general_characteristics['height_mean'] = sum(list_height) / len(list_height)\n",
        "  general_characteristics['frames_mean'] = sum(list_frames) / len(list_frames)\n",
        "  general_characteristics['fps_mean'] = sum(list_fps) / len(list_fps)\n",
        "  general_characteristics['seconds_mean'] = sum(list_seconds) / len(list_seconds)\n",
        "\n",
        "  return general_characteristics"
      ],
      "metadata": {
        "id": "Nu7B2Bq9pH7z"
      },
      "id": "Nu7B2Bq9pH7z",
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "x1eiluCeN6W8",
      "metadata": {
        "id": "x1eiluCeN6W8"
      },
      "source": [
        "### **Analisis de datos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "id": "msSmnRxi2nRC",
      "metadata": {
        "id": "msSmnRxi2nRC"
      },
      "outputs": [],
      "source": [
        "dataset_path = f\"/content/dataset\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cantidad y tipo de archivos a analizar"
      ],
      "metadata": {
        "id": "DQST6jyifNOQ"
      },
      "id": "DQST6jyifNOQ"
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "id": "w4HOQekdD_nB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4HOQekdD_nB",
        "outputId": "f63cdff6-d5ed-4f6c-83e1-b3c3b1adf2b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de archivos en total = 1753\n",
            " - Extension .json tiene 944\n",
            " - Extension .mp4 tiene 809\n"
          ]
        }
      ],
      "source": [
        "listed_files = get_all_files(f\"{dataset_path}\")\n",
        "print(f\"Cantidad de archivos en total = {len(listed_files)}\")\n",
        "\n",
        "\n",
        "files_by_ext = get_listed_files_with_types(listed_files)\n",
        "\n",
        "for k, v in files_by_ext.items():\n",
        "    print(f\" - Extension {k} tiene {len(v)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cantidad de videos de entranamiento y validacion"
      ],
      "metadata": {
        "id": "6Wi4C_9hfw4q"
      },
      "id": "6Wi4C_9hfw4q"
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "id": "G4ncU_s3Ebc5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4ncU_s3Ebc5",
        "outputId": "1383baf6-a7c3-4a0c-f643-f9582ca1b039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de archivos a utilizar = 600\n",
            " - train tiene 403\n",
            " - val tiene 197\n"
          ]
        }
      ],
      "source": [
        "files_overhead_view = []\n",
        "files_overhead_view_by_type = {\n",
        "    'train': [],\n",
        "    'val': [],\n",
        "}\n",
        "\n",
        "for mp4 in files_by_ext['.mp4']:\n",
        "    if not f\"{dataset_path}/external\" in mp4 and not \"vehicle_view\" in  mp4:\n",
        "        files_overhead_view.append(mp4)\n",
        "        #omitir ruta videos al leer desde colab (videos/train)\n",
        "        if \"train\" in mp4:\n",
        "            files_overhead_view_by_type['train'].append(mp4)\n",
        "        #omitir ruta videos al leer desde colab (videos/train)\n",
        "        elif \"val\" in mp4:\n",
        "            files_overhead_view_by_type['val'].append(mp4)\n",
        "        else:\n",
        "            print(f\"W: No train ni val. Que es? {mp4}\")\n",
        "\n",
        "\n",
        "print(f\"Cantidad de archivos a utilizar = {len(files_overhead_view)}\")\n",
        "for k, v in files_overhead_view_by_type.items():\n",
        "    print(f\" - {k} tiene {len(v)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "id": "vMq5YWzoX_7b",
      "metadata": {
        "id": "vMq5YWzoX_7b"
      },
      "outputs": [],
      "source": [
        "train_files_overhead_view = [f for f in  files_overhead_view if 'train' in f]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "id": "HbdSmgiEewxL",
      "metadata": {
        "id": "HbdSmgiEewxL"
      },
      "outputs": [],
      "source": [
        "val_files_overhead_view = [f for f in  files_overhead_view if 'val' in f]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generacion de un pandas dataframe con las caracteristicas generales de los videos (frames number, width, height, fps)"
      ],
      "metadata": {
        "id": "2zbSONwsf_uZ"
      },
      "id": "2zbSONwsf_uZ"
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = get_cap_dataframe(train_files_overhead_view)"
      ],
      "metadata": {
        "id": "bf1R7p_kdTeH"
      },
      "id": "bf1R7p_kdTeH",
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hze1kePocWLG",
        "outputId": "93ee88ee-8c9d-4c90-9f17-a83c77a647be"
      },
      "id": "hze1kePocWLG",
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          video_path  num_frames  frame_width  \\\n",
              "0  /content/dataset/train/20231013_114328_normal_...        1937         1920   \n",
              "1  /content/dataset/train/20230728_4_CN32_T1_Came...        2296         1920   \n",
              "2  /content/dataset/train/20231006_27_SN19_T3_192...        2211         1920   \n",
              "3  /content/dataset/train/20231013_114328_normal_...        1898         1920   \n",
              "4  /content/dataset/train/20231013_101813_normal_...        2250         1920   \n",
              "\n",
              "   frame_height  fps  \n",
              "0          1080   30  \n",
              "1          1080   30  \n",
              "2          1080   30  \n",
              "3          1080   30  \n",
              "4          1080   29  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9d44d9f-3fac-4ab2-9976-b5afe3521517\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_path</th>\n",
              "      <th>num_frames</th>\n",
              "      <th>frame_width</th>\n",
              "      <th>frame_height</th>\n",
              "      <th>fps</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/dataset/train/20231013_114328_normal_...</td>\n",
              "      <td>1937</td>\n",
              "      <td>1920</td>\n",
              "      <td>1080</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/dataset/train/20230728_4_CN32_T1_Came...</td>\n",
              "      <td>2296</td>\n",
              "      <td>1920</td>\n",
              "      <td>1080</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/dataset/train/20231006_27_SN19_T3_192...</td>\n",
              "      <td>2211</td>\n",
              "      <td>1920</td>\n",
              "      <td>1080</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/dataset/train/20231013_114328_normal_...</td>\n",
              "      <td>1898</td>\n",
              "      <td>1920</td>\n",
              "      <td>1080</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/dataset/train/20231013_101813_normal_...</td>\n",
              "      <td>2250</td>\n",
              "      <td>1920</td>\n",
              "      <td>1080</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9d44d9f-3fac-4ab2-9976-b5afe3521517')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f9d44d9f-3fac-4ab2-9976-b5afe3521517 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f9d44d9f-3fac-4ab2-9976-b5afe3521517');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fccdd0d3-3f56-4fed-ba3b-188ddb770102\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fccdd0d3-3f56-4fed-ba3b-188ddb770102')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fccdd0d3-3f56-4fed-ba3b-188ddb770102 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 403,\n  \"fields\": [\n    {\n      \"column\": \"video_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 403,\n        \"samples\": [\n          \"/content/dataset/train/20230728_15_SY18_T2_Camera3_0.mp4\",\n          \"/content/dataset/train/20231006_25_SN20_T1_192.168.0.11_1.mp4\",\n          \"/content/dataset/train/20231013_104036_normal_192.168.0.13_4_event_0.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_frames\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 572,\n        \"min\": 1861,\n        \"max\": 7735,\n        \"num_unique_values\": 155,\n        \"samples\": [\n          1899,\n          2316,\n          2345\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frame_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1920,\n        \"max\": 1920,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1920\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frame_height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1080,\n        \"max\": 1080,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1080\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 29,\n        \"max\": 30,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          29\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_val = get_cap_dataframe(val_files_overhead_view)"
      ],
      "metadata": {
        "id": "Fmw-s58OemVO"
      },
      "id": "Fmw-s58OemVO",
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_val.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "N7DnGoHgeoRy",
        "outputId": "54c75671-adf9-4d46-dab3-5fd1b17ce950"
      },
      "id": "N7DnGoHgeoRy",
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          video_path  num_frames  frame_width  \\\n",
              "0  /content/dataset/val/20230929_13_SN25_T1_192.1...        2139         1920   \n",
              "1  /content/dataset/val/20230929_65_SN4_T1_192.16...        2139         1920   \n",
              "2  /content/dataset/val/20231013_114328_normal_19...        1888         1920   \n",
              "3  /content/dataset/val/20230728_37_CN38_T1_Camer...        2231         1920   \n",
              "4  /content/dataset/val/20231013_101845_normal_19...        2029         1920   \n",
              "\n",
              "   frame_height  fps  \n",
              "0          1080   30  \n",
              "1          1080   30  \n",
              "2          1080   30  \n",
              "3          1080   30  \n",
              "4          1080   30  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70e90607-a69a-471c-baa6-507de33716dd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_path</th>\n",
              "      <th>num_frames</th>\n",
              "      <th>frame_width</th>\n",
              "      <th>frame_height</th>\n",
              "      <th>fps</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/dataset/val/20230929_13_SN25_T1_192.1...</td>\n",
              "      <td>2139</td>\n",
              "      <td>1920</td>\n",
              "      <td>1080</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/dataset/val/20230929_65_SN4_T1_192.16...</td>\n",
              "      <td>2139</td>\n",
              "      <td>1920</td>\n",
              "      <td>1080</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/dataset/val/20231013_114328_normal_19...</td>\n",
              "      <td>1888</td>\n",
              "      <td>1920</td>\n",
              "      <td>1080</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/dataset/val/20230728_37_CN38_T1_Camer...</td>\n",
              "      <td>2231</td>\n",
              "      <td>1920</td>\n",
              "      <td>1080</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/dataset/val/20231013_101845_normal_19...</td>\n",
              "      <td>2029</td>\n",
              "      <td>1920</td>\n",
              "      <td>1080</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70e90607-a69a-471c-baa6-507de33716dd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-70e90607-a69a-471c-baa6-507de33716dd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-70e90607-a69a-471c-baa6-507de33716dd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4825eb38-e1b2-4ed7-af93-0dff6bbd6a45\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4825eb38-e1b2-4ed7-af93-0dff6bbd6a45')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4825eb38-e1b2-4ed7-af93-0dff6bbd6a45 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_val",
              "summary": "{\n  \"name\": \"df_val\",\n  \"rows\": 197,\n  \"fields\": [\n    {\n      \"column\": \"video_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 197,\n        \"samples\": [\n          \"/content/dataset/val/20230728_58_SY15_T1_Camera3_1.mp4\",\n          \"/content/dataset/val/20230728_28_SN20_T1_Camera4_2.mp4\",\n          \"/content/dataset/val/20230728_27_CN34_T1_Camera1_3.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_frames\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 136,\n        \"min\": 1873,\n        \"max\": 2493,\n        \"num_unique_values\": 78,\n        \"samples\": [\n          2138,\n          2139,\n          2026\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frame_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 47,\n        \"min\": 1920,\n        \"max\": 2592,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2592,\n          1920\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frame_height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 61,\n        \"min\": 1080,\n        \"max\": 1944,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1944,\n          1080\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 30,\n        \"max\": 30,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          30\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Anotaciones de los videos de entrenamiento y validacion"
      ],
      "metadata": {
        "id": "3NA1vJfFStO7"
      },
      "id": "3NA1vJfFStO7"
    },
    {
      "cell_type": "code",
      "source": [
        "annotations = []\n",
        "\n",
        "for j in files_by_ext['.json']:\n",
        "    annotations.append(j)\n",
        "\n",
        "print(f\"Cantidad de archivos a utilizar = {len(annotations)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZWl8TS3S3V8",
        "outputId": "271ac948-3c0b-4a88-ec2e-dd57a0d7709b"
      },
      "id": "wZWl8TS3S3V8",
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de archivos a utilizar = 944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generacion de un pandas dataframe para la ruta de las anotaciones"
      ],
      "metadata": {
        "id": "wueBOl4BVSG8"
      },
      "id": "wueBOl4BVSG8"
    },
    {
      "cell_type": "code",
      "source": [
        "df_annot = pd.DataFrame(annotations, columns=['annotation_path'])"
      ],
      "metadata": {
        "id": "FTqYrHItVCWV"
      },
      "id": "FTqYrHItVCWV",
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_annot.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pCRikO5RVb7G",
        "outputId": "e6ec711e-0a05-4c46-f6bc-eb8e66a62c2b"
      },
      "id": "pCRikO5RVb7G",
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     annotation_path\n",
              "0  /content/dataset/annotations/20230929_54_SN38_...\n",
              "1  /content/dataset/annotations/20230929_59_SN41_...\n",
              "2  /content/dataset/annotations/20230728_37_CN38_...\n",
              "3  /content/dataset/annotations/20230922_34_CN11_...\n",
              "4  /content/dataset/annotations/20230929_20_CY20_..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e2b38f6-3dcb-4a78-9db6-08d63d4ea13d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotation_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/dataset/annotations/20230929_54_SN38_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/dataset/annotations/20230929_59_SN41_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/dataset/annotations/20230728_37_CN38_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/dataset/annotations/20230922_34_CN11_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/dataset/annotations/20230929_20_CY20_...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e2b38f6-3dcb-4a78-9db6-08d63d4ea13d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3e2b38f6-3dcb-4a78-9db6-08d63d4ea13d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3e2b38f6-3dcb-4a78-9db6-08d63d4ea13d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4c1cb27a-3e5c-4a37-8da5-781717920059\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4c1cb27a-3e5c-4a37-8da5-781717920059')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4c1cb27a-3e5c-4a37-8da5-781717920059 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_annot",
              "summary": "{\n  \"name\": \"df_annot\",\n  \"rows\": 944,\n  \"fields\": [\n    {\n      \"column\": \"annotation_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 944,\n        \"samples\": [\n          \"/content/dataset/annotations/20230728_23_SY20_T1_caption.json\",\n          \"/content/dataset/annotations/20230929_56_SY20_T1_192.168.0.11_1_bbox.json\",\n          \"/content/dataset/annotations/20231013_101845_normal_192.168.0.14_4_event_2_bbox.json\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejecucion de un video aleatorio"
      ],
      "metadata": {
        "id": "iXm96avUgg16"
      },
      "id": "iXm96avUgg16"
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "id": "7T6lurMTe9Uw",
      "metadata": {
        "id": "7T6lurMTe9Uw"
      },
      "outputs": [],
      "source": [
        "video_path = get_radom_file(train_files_overhead_view)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Bx6LeF3la5we",
      "metadata": {
        "id": "Bx6LeF3la5we"
      },
      "outputs": [],
      "source": [
        "play_video(video_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtencion de la anotacion del video"
      ],
      "metadata": {
        "id": "m3gDeFZGg4X8"
      },
      "id": "m3gDeFZGg4X8"
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "id": "Roteqc52ezt2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Roteqc52ezt2",
        "outputId": "de21fe58-8d67-4b81-8841-ac50f1f2762a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'vehicle_view': '20230929_61_CN35_T1_vehicle_view.mp4',\n",
              " 'event_phase': [{'labels': ['4'],\n",
              "   'caption_pedestrian': \"The pedestrian, a young man in his twenties, stands diagonally to the right of the vehicle, completely unaware of its presence. He is positioned directly in front of the car, close in distance. His body is motionless and his line of sight is immediately above. The pedestrian's attire consists of a black T-shirt and black slacks, matching the dark and cloudy weather. The road conditions are favorable, with the dry asphalt providing a level surface. The residential road intersects with a signal, indicating that both the vehicle and the pedestrian should exercise caution. Although the traffic volume is light, there are two-way lanes available. On this particular street, there are no sidewalks or roadside strips on both sides, but there are street lights illuminating the path. This simple event captures a snapshot of the pedestrian's surroundings and his lack of awareness towards the vehicle approaching him.\",\n",
              "   'caption_vehicle': 'The vehicle is on the left side of the pedestrian and is close to them. The pedestrian is visible to the vehicle and it takes emergency action by braking to avoid a collision. The vehicle is stationary, with a speed of 0 km/h. The environment conditions reveal that the pedestrian is a male in his 20s, approximately 170 cm tall. He is wearing a black T-shirt and black slacks. The weather is cloudy, with low brightness and dry road surface conditions. The road is level and made of asphalt. The traffic volume is light on this residential road, which has two-way traffic. The event takes place at an intersection with signal lights. There is no sidewalk on both sides and no roadside strip. However, there are street lights illuminating the area. Overall, the vehicle maintains a safe distance from the pedestrian and takes prompt action to avoid any potential danger, considering the environmental conditions and road characteristics.',\n",
              "   'start_time': '4.027',\n",
              "   'end_time': '6.818'},\n",
              "  {'labels': ['3'],\n",
              "   'caption_pedestrian': \"The pedestrian, a male in his 20s with a height of 170 cm, was standing still on a residential road intersection with signal. He was diagonally positioned to the right, in the same direction as the vehicle, and directly in front of it. Unaware of the vehicle's presence, his line of sight was immediately above. The pedestrian's body language showed no signs of abnormal activity, as he was calmly standing still. He was wearing a black T-shirt on his upper body and black slacks on his lower body. The weather was cloudy, resulting in a dark brightness. The road surface was dry and level, made of asphalt. The traffic volume was light on the two-way traffic residential road. There were no sidewalks on both sides, and neither were there roadside strips. However, street lights were available, providing illumination. The overall conditions of the environment indicate that the pedestrian was stationary in a potentially unsafe position, with limited visibility due to the darkness and cloudy weather.\",\n",
              "   'caption_vehicle': \"The vehicle is positioned on the left side of the pedestrian, and it is close in relative distance. The vehicle's field of view indicates that the pedestrian is visible. The vehicle is currently turning right at a speed of 20 km/h. In terms of the environment conditions, the pedestrian is a male in his 20s, with a height of 170 cm. He is wearing a black T-shirt for the upper body and black slacks for the lower body. The weather is cloudy and the brightness level is dark. The road surface conditions are dry and level, with asphalt as the road surface type. The traffic volume is light and the road classification is a residential road with two-way traffic. The road form is an intersection with a signal. There is no sidewalk or roadside strip on both sides, but street lights are present. With this information, it can be described that the vehicle is currently in the process of making a right turn while being aware of the pedestrian's presence on the left side.\",\n",
              "   'start_time': '3.004',\n",
              "   'end_time': '4.025'},\n",
              "  {'labels': ['2'],\n",
              "   'caption_pedestrian': \"The pedestrian is a male in his 20s, approximately 170 cm tall, wearing a black T-shirt and black slacks. He is standing diagonally to the right, in front of the vehicle, with his body oriented diagonally to the right as well, in the same direction as the vehicle. The pedestrian is close to the vehicle, and his line of sight is immediately above. He is unaware of the vehicle's presence. The overall environment is cloudy and dark, with a dry asphalt road surface. The road is a residential road with two-way traffic and an intersection with a signal. There are no sidewalks on both sides, and there are no roadside strips; however, there are street lights present. The pedestrian's general action is to stand still, but his abnormal action is lying stretched out. The traffic volume is light.\",\n",
              "   'caption_vehicle': 'The vehicle, traveling at a speed of 20 km/h, was positioned behind and to the left of the pedestrian. The vehicle was at a close distance to the pedestrian and had a clear view of them. It started to turn right. The vehicle and the pedestrian were on a residential road, which had two-way traffic. The road was dry, level, and made of asphalt. The vehicle and pedestrian were at an intersection with a traffic signal in place. The environment conditions indicated that the pedestrian was a male in his 20s, with a height of 170 cm. He was wearing a black T-shirt and black slacks. The weather was cloudy, and it was dark outside. The road had light traffic volume and was not illuminated by street lights. There was no sidewalk and no roadside strip on either side of the road.',\n",
              "   'start_time': '2.007',\n",
              "   'end_time': '3.001'},\n",
              "  {'labels': ['1'],\n",
              "   'caption_pedestrian': \"In a residential road intersection on a cloudy day, a male pedestrian in his 20s with a height of 170 cm stands diagonally to the right, in front of a vehicle. The pedestrian is wearing a black T-shirt and black slacks. With his line of sight immediately above, he remains unaware of the vehicle's presence, which is positioned near him. The road conditions are dry and level with a light traffic volume. The road surface is asphalt, and there are two lanes for two-way traffic. Although the surroundings are dark, street lights illuminate the area. The pedestrian is standing still, not moving or taking any abnormal actions. As far as the environment is concerned, there are no sidewalks on both sides, nor are there roadside strips on both sides. Despite the environmental factors and proximity to the vehicle, the pedestrian appears to be uninformed about its existence and continues to remain stationary.\",\n",
              "   'caption_vehicle': \"The vehicle is positioned behind on the left of the pedestrian and is relatively near to them. The pedestrian is within the vehicle's field of view, indicating visibility. The vehicle is moving straight ahead at a speed of 20 km/h. The road surface conditions are dry, and the road is level. The vehicle is traveling on a two-way traffic residential road, approaching an intersection with a signal. The environment conditions indicate that the pedestrian is a male in his 20s, standing at a height of 170 cm. He is wearing a black T-shirt on the upper body and black slacks on the lower body. The weather is cloudy, and the brightness is dark. The road surface is asphalt, and the traffic volume is light. There are no sidewalks on both sides of the road, and only one side has a roadside strip. Street lights are present. This information describes the scenario in which the vehicle is operating.\",\n",
              "   'start_time': '1.008',\n",
              "   'end_time': '2.004'},\n",
              "  {'labels': ['0'],\n",
              "   'caption_pedestrian': \"The pedestrian, a male in his 20s with a height of 170 cm, was wearing a black T-shirt and black slacks. It was a cloudy and dark day, with the road being dry and the traffic volume light. He was standing diagonally to the right, in front of a vehicle on a residential road intersection with a signal. The pedestrian's body orientation was the same direction as the vehicle, and his line of sight was immediately above. He was closely watching his surroundings, but unaware of the vehicle approaching him. Despite the pedestrian being near the vehicle, the pedestrian was standing still. However, an abnormal action was noticed as he was lying stretched out. The environment condition portrayed a typical urban setting, with asphalt as the road surface type and a two-way traffic road with not both sides having a sidewalk and roadside strip. Street lights were present in the surroundings.\",\n",
              "   'caption_vehicle': \"The vehicle, traveling at a speed of 20 km/h, is positioned behind to the left of a pedestrian. The relative distance between the vehicle and the pedestrian is near. From the vehicle's field of view, the pedestrian is visible. The vehicle is currently going straight ahead. The environment conditions surrounding the vehicle and the pedestrian are as follows: The pedestrian is a male in his 20s, with a height of 170 cm. He is wearing a black T-shirt and black slacks. The weather is cloudy, and the brightness level is dark. The road surface conditions are dry and level, with asphalt as the road surface type. The traffic volume is light on this residential road, which has two-way traffic and an intersection with a signal. There are no sidewalks or roadside strips on both sides of the road, but street lights are present.\",\n",
              "   'start_time': '0.00',\n",
              "   'end_time': '1.008'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ],
      "source": [
        "get_annotation(video_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "id": "13ISblRnd039",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "13ISblRnd039",
        "outputId": "ad99b235-c1b2-4532-c6df-72a63857ac1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Duration in seconds: 73.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 194
        }
      ],
      "source": [
        "get_video_duration_in_seconds(video_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "props = get_video_properties(video_path)"
      ],
      "metadata": {
        "id": "WHPLDBTRowtQ"
      },
      "id": "WHPLDBTRowtQ",
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "props"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAF--rqMoyND",
        "outputId": "713af412-fb59-4c19-b471-a3939bc7330b"
      },
      "id": "lAF--rqMoyND",
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'index': 0,\n",
              " 'codec_name': 'h264',\n",
              " 'codec_long_name': 'H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10',\n",
              " 'profile': 'High',\n",
              " 'codec_type': 'video',\n",
              " 'codec_tag_string': 'avc1',\n",
              " 'codec_tag': '0x31637661',\n",
              " 'width': 1920,\n",
              " 'height': 1080,\n",
              " 'coded_width': 1920,\n",
              " 'coded_height': 1080,\n",
              " 'closed_captions': 0,\n",
              " 'has_b_frames': 2,\n",
              " 'sample_aspect_ratio': '1:1',\n",
              " 'display_aspect_ratio': '16:9',\n",
              " 'pix_fmt': 'yuvj420p',\n",
              " 'level': 40,\n",
              " 'color_range': 'pc',\n",
              " 'chroma_location': 'left',\n",
              " 'refs': 1,\n",
              " 'is_avc': 'true',\n",
              " 'nal_length_size': '4',\n",
              " 'r_frame_rate': '30/1',\n",
              " 'avg_frame_rate': '30/1',\n",
              " 'time_base': '1/15360',\n",
              " 'start_pts': 0,\n",
              " 'start_time': '0.000000',\n",
              " 'duration_ts': 1131008,\n",
              " 'duration': '73.633333',\n",
              " 'bit_rate': '9664631',\n",
              " 'bits_per_raw_sample': '8',\n",
              " 'nb_frames': '2209',\n",
              " 'disposition': {'default': 1,\n",
              "  'dub': 0,\n",
              "  'original': 0,\n",
              "  'comment': 0,\n",
              "  'lyrics': 0,\n",
              "  'karaoke': 0,\n",
              "  'forced': 0,\n",
              "  'hearing_impaired': 0,\n",
              "  'visual_impaired': 0,\n",
              "  'clean_effects': 0,\n",
              "  'attached_pic': 0,\n",
              "  'timed_thumbnails': 0},\n",
              " 'tags': {'language': 'eng',\n",
              "  'handler_name': 'VideoHandler',\n",
              "  'vendor_id': '[0][0][0][0]'}}"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YDVFBXRYgCQV",
      "metadata": {
        "id": "YDVFBXRYgCQV"
      },
      "source": [
        "### Estadisticas para los datos de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "YYFr7CSniPpK",
        "outputId": "99d2c72a-0936-40c1-fc03-c15d66d449b9"
      },
      "id": "YYFr7CSniPpK",
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          video_path  num_frames  frame_width  \\\n",
              "0  /content/dataset/train/20231013_114328_normal_...        1937         1920   \n",
              "1  /content/dataset/train/20230728_4_CN32_T1_Came...        2296         1920   \n",
              "2  /content/dataset/train/20231006_27_SN19_T3_192...        2211         1920   \n",
              "\n",
              "   frame_height  fps  \n",
              "0          1080   30  \n",
              "1          1080   30  \n",
              "2          1080   30  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43f7f838-bf0b-4614-a77c-133a28b96aee\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_path</th>\n",
              "      <th>num_frames</th>\n",
              "      <th>frame_width</th>\n",
              "      <th>frame_height</th>\n",
              "      <th>fps</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/dataset/train/20231013_114328_normal_...</td>\n",
              "      <td>1937</td>\n",
              "      <td>1920</td>\n",
              "      <td>1080</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/dataset/train/20230728_4_CN32_T1_Came...</td>\n",
              "      <td>2296</td>\n",
              "      <td>1920</td>\n",
              "      <td>1080</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/dataset/train/20231006_27_SN19_T3_192...</td>\n",
              "      <td>2211</td>\n",
              "      <td>1920</td>\n",
              "      <td>1080</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43f7f838-bf0b-4614-a77c-133a28b96aee')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-43f7f838-bf0b-4614-a77c-133a28b96aee button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-43f7f838-bf0b-4614-a77c-133a28b96aee');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cf8a9899-1029-4e4e-b7ca-c3abecbb3d12\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cf8a9899-1029-4e4e-b7ca-c3abecbb3d12')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cf8a9899-1029-4e4e-b7ca-c3abecbb3d12 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 403,\n  \"fields\": [\n    {\n      \"column\": \"video_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 403,\n        \"samples\": [\n          \"/content/dataset/train/20230728_15_SY18_T2_Camera3_0.mp4\",\n          \"/content/dataset/train/20231006_25_SN20_T1_192.168.0.11_1.mp4\",\n          \"/content/dataset/train/20231013_104036_normal_192.168.0.13_4_event_0.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_frames\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 572,\n        \"min\": 1861,\n        \"max\": 7735,\n        \"num_unique_values\": 155,\n        \"samples\": [\n          1899,\n          2316,\n          2345\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frame_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1920,\n        \"max\": 1920,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1920\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frame_height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1080,\n        \"max\": 1080,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1080\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 29,\n        \"max\": 30,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          29\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "id": "U7BjJkyMifga",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7BjJkyMifga",
        "outputId": "17c0c7ee-97a7-474a-9dce-bef746a69bb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'width_mean': 1920.0,\n",
              " 'height_mean': 1080.0,\n",
              " 'frames_mean': 2239.2952853598017,\n",
              " 'fps_mean': 29.98759305210918,\n",
              " 'seconds_mean': 74.67660363366703}"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ],
      "source": [
        "get_video_characteristics(df_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Estadisticas para los datos de validacion"
      ],
      "metadata": {
        "id": "uED6wgiOo8TM"
      },
      "id": "uED6wgiOo8TM"
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "id": "QsUD3t-CS1Vb",
      "metadata": {
        "id": "QsUD3t-CS1Vb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "68b5d0a8-3cc6-4379-83f4-5c78383d1dab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          video_path  num_frames  frame_width  \\\n",
              "0  /content/dataset/val/20230929_13_SN25_T1_192.1...        2139         1920   \n",
              "1  /content/dataset/val/20230929_65_SN4_T1_192.16...        2139         1920   \n",
              "2  /content/dataset/val/20231013_114328_normal_19...        1888         1920   \n",
              "\n",
              "   frame_height  fps  \n",
              "0          1080   30  \n",
              "1          1080   30  \n",
              "2          1080   30  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c0bcbd5-fd95-4ac4-adbf-b646a5fb2764\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_path</th>\n",
              "      <th>num_frames</th>\n",
              "      <th>frame_width</th>\n",
              "      <th>frame_height</th>\n",
              "      <th>fps</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/dataset/val/20230929_13_SN25_T1_192.1...</td>\n",
              "      <td>2139</td>\n",
              "      <td>1920</td>\n",
              "      <td>1080</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/dataset/val/20230929_65_SN4_T1_192.16...</td>\n",
              "      <td>2139</td>\n",
              "      <td>1920</td>\n",
              "      <td>1080</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/dataset/val/20231013_114328_normal_19...</td>\n",
              "      <td>1888</td>\n",
              "      <td>1920</td>\n",
              "      <td>1080</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c0bcbd5-fd95-4ac4-adbf-b646a5fb2764')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3c0bcbd5-fd95-4ac4-adbf-b646a5fb2764 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3c0bcbd5-fd95-4ac4-adbf-b646a5fb2764');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0e859acc-b11d-43ea-bfb3-cb3e439f00dd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0e859acc-b11d-43ea-bfb3-cb3e439f00dd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0e859acc-b11d-43ea-bfb3-cb3e439f00dd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_val",
              "summary": "{\n  \"name\": \"df_val\",\n  \"rows\": 197,\n  \"fields\": [\n    {\n      \"column\": \"video_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 197,\n        \"samples\": [\n          \"/content/dataset/val/20230728_58_SY15_T1_Camera3_1.mp4\",\n          \"/content/dataset/val/20230728_28_SN20_T1_Camera4_2.mp4\",\n          \"/content/dataset/val/20230728_27_CN34_T1_Camera1_3.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_frames\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 136,\n        \"min\": 1873,\n        \"max\": 2493,\n        \"num_unique_values\": 78,\n        \"samples\": [\n          2138,\n          2139,\n          2026\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frame_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 47,\n        \"min\": 1920,\n        \"max\": 2592,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2592,\n          1920\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frame_height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 61,\n        \"min\": 1080,\n        \"max\": 1944,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1944,\n          1080\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 30,\n        \"max\": 30,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          30\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 199
        }
      ],
      "source": [
        "df_val.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "id": "djzPv0kElX3w",
      "metadata": {
        "id": "djzPv0kElX3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4a825a1-46e8-497a-8100-a17a058eb8a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'width_mean': 1923.4111675126903,\n",
              " 'height_mean': 1084.3857868020305,\n",
              " 'frames_mean': 2165.1522842639592,\n",
              " 'fps_mean': 30.0,\n",
              " 'seconds_mean': 72.17174280879857}"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ],
      "source": [
        "get_video_characteristics(df_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ingenieria de caracteristicas**"
      ],
      "metadata": {
        "id": "TW_3QYK-tWK7"
      },
      "id": "TW_3QYK-tWK7"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_preprocessing_of_annotation(text):\n",
        "  \"\"\"\n",
        "  Funcion que obtiene el preprocesamiento de una anotacion.\n",
        "  \"\"\"\n",
        "  #Minusculas\n",
        "  text = text.lower()\n",
        "\n",
        "  #Remover puntuacion\n",
        "  text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "  #Remover stop words\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "\n",
        "  #Lemantizacion\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "Sw89LX3R-LBc"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Sw89LX3R-LBc"
    },
    {
      "cell_type": "code",
      "source": [
        "def write_annotation_preprocess(df_tmp):\n",
        "  \"\"\"\n",
        "  Funcion que obtiene la anotacion preprocesada.\n",
        "  \"\"\"\n",
        "  for i, row in df_tmp.iterrows():\n",
        "\n",
        "    if 'caption' in row['annotation_path']:\n",
        "\n",
        "      with open(row['annotation_path'], 'r') as input_file:\n",
        "        data_tmp = json.load(input_file)\n",
        "\n",
        "      for i, j in enumerate(data_tmp['event_phase']):\n",
        "        data_tmp['event_phase'][i]['caption_pedestrian'] = get_preprocessing_of_annotation(data_tmp['event_phase'][i]['caption_pedestrian'])\n",
        "        data_tmp['event_phase'][i]['caption_vehicle'] = get_preprocessing_of_annotation(data_tmp['event_phase'][i]['caption_vehicle'])\n",
        "\n",
        "        with open(row['annotation_path'].replace('annotations', 'annotations_preprocess'), 'w') as output_file:\n",
        "          json.dump(data_tmp, output_file)\n",
        "    else:\n",
        "      pass"
      ],
      "metadata": {
        "id": "qr_SsOvb-LBc"
      },
      "execution_count": null,
      "outputs": [],
      "id": "qr_SsOvb-LBc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hrzyts-jlY9z"
      },
      "outputs": [],
      "source": [
        "def feature_engineering(annotation_tmp):\n",
        "  \"\"\"\n",
        "  Funcion que realiza la ingenieria de caracteristicas.\n",
        "  \"\"\"\n",
        "  vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "  vectorizer.fit(annotation_tmp)\n",
        "\n",
        "  feature_matrix = vectorizer.transform(annotation_tmp)\n",
        "\n",
        "  return feature_matrix"
      ],
      "id": "Hrzyts-jlY9z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alRIoRRvlbtF"
      },
      "outputs": [],
      "source": [
        "def clustering(feature_matrix, num_clusters=5):\n",
        "  \"\"\"\n",
        "  Funcion que realiza el clustering.\n",
        "  \"\"\"\n",
        "  kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
        "\n",
        "  kmeans.fit(feature_matrix)\n",
        "\n",
        "  cluster_assigments = kmeans.labels_\n",
        "\n",
        "  return cluster_assigments"
      ],
      "id": "alRIoRRvlbtF"
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TTHPvL96T41",
        "outputId": "58e4a8b6-3c6f-4b03-8dc4-1679bef4266a"
      },
      "id": "1TTHPvL96T41",
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Se crea un nuevo folder para los datos pre-procesados"
      ],
      "metadata": {
        "id": "kSmYK8PisyHI"
      },
      "id": "kSmYK8PisyHI"
    },
    {
      "cell_type": "code",
      "source": [
        "make_folder('dataset/annotations_preprocess')"
      ],
      "metadata": {
        "id": "5PXbpqajG5Uf"
      },
      "id": "5PXbpqajG5Uf",
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Se aplica el preprocesamiento y se escriben los archivos en el nuevo folder"
      ],
      "metadata": {
        "id": "B_o8Qr_TtFUe"
      },
      "id": "B_o8Qr_TtFUe"
    },
    {
      "cell_type": "code",
      "source": [
        "write_annotation_preprocess(df_annot)"
      ],
      "metadata": {
        "id": "-9HB8iPyZIRW"
      },
      "id": "-9HB8iPyZIRW",
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Archivo sin procesamiento"
      ],
      "metadata": {
        "id": "_4SN13_Mwnoe"
      },
      "id": "_4SN13_Mwnoe"
    },
    {
      "cell_type": "code",
      "source": [
        "get_annotation('dataset/annotations/20230707_12_SN17_T1_caption.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRbhTRjvuQda",
        "outputId": "2afcc55a-fc16-49b4-aafc-67266c94ec61"
      },
      "id": "PRbhTRjvuQda",
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'vehicle_view': '20230707_12_SN17_T1_vehicle_view.mp4',\n",
              " 'event_phase': [{'labels': ['4'],\n",
              "   'caption_pedestrian': 'The pedestrian, a male in his 30s approximately 170 cm tall, was wearing a black T-shirt and black slacks. It was a clear and bright day with dry road conditions on a residential road with two-way traffic. There were no sidewalks on both sides, and street lights were present. The pedestrian was positioned directly in front of a vehicle, facing the opposite direction. The pedestrian noticed the vehicle and was slowly moving in front of it. Suddenly, a collision occurred.',\n",
              "   'caption_vehicle': 'The vehicle is positioned in front of a pedestrian, close in proximity. The vehicle has a clear field of view, as the pedestrian is visible. The vehicle is currently stopped and its speed is 0 km/h. The gender of the pedestrian is male, in his 30s with a height of 170 cm. He is wearing a black T-shirt on the upper body and black slacks on the lower body. The weather is clear and the brightness is bright. The road surface conditions are dry and the road is level with asphalt. The traffic volume is usual on this two-way residential road. There is no sidewalk on both sides, and both the roadside strip and street lights are present.',\n",
              "   'start_time': '9.476',\n",
              "   'end_time': '14.017'},\n",
              "  {'labels': ['3'],\n",
              "   'caption_pedestrian': 'The pedestrian, a male in his 30s, stood perpendicular to the vehicle and to the right of it. He was directly in front of the vehicle, positioned closely. His line of sight was focused on the road surface, indicating he was closely watching. Moving slowly, the pedestrian was in front of the vehicle and appeared to be crossing. He wore a black T-shirt on his upper body and black slacks on his lower body. The weather was clear with bright brightness. The road surface was dry and leveled asphalt. The traffic volume on the two-way residential road was usual. Both sides of the road did not have a sidewalk or roadside strip, but there were street lights. This set of data provides a detailed description of the pedestrian and the surrounding environment in a third-person narrative style.',\n",
              "   'caption_vehicle': \"The vehicle is positioned on the right side of the pedestrian and is in close proximity to them. From the vehicle's field of view, the pedestrian is visible. The vehicle is going straight ahead at a speed of 5 km/h. The environment conditions include a male pedestrian in his 30s, standing at a height of 170 cm. He is wearing a black T-shirt for his upper body and black slacks for his lower body. The weather is clear and the brightness is bright. The road surface conditions are dry and the road is level with asphalt. The traffic volume is usual on this residential road with two-way traffic. There is no sidewalk available on both sides, and the roadside strip is also absent. Street lights are present in the surroundings.\",\n",
              "   'start_time': '5.383',\n",
              "   'end_time': '9.420'},\n",
              "  {'labels': ['2'],\n",
              "   'caption_pedestrian': \"A man in his 30s wearing a black T-shirt and black slacks stands diagonally to the left of a vehicle on a residential road. His body is positioned perpendicular to the vehicle and to the right. The man's height is approximately 170 cm. The weather is clear, and the brightness is bright. The road surface is dry and level, made of asphalt. There are two-way traffic lanes, but there is no sidewalk or roadside strip on both sides of the road. Street lights illuminate the surroundings. Despite noticing the vehicle, the pedestrian, moving slowly, seems to be slowly looking around, possibly unaware of the vehicle's presence. The pedestrian is about to cross the road, intending to travel in front of the vehicle. The traffic volume is usual, creating a typical scenario for the pedestrian.\",\n",
              "   'caption_vehicle': \"The vehicle is positioned diagonally to the right in front of the pedestrian and is at a close distance from them. The pedestrian is visible within the vehicle's field of view. The vehicle is currently stopped and its speed is 0 km/h. The driver is observing the surroundings and waiting for the appropriate moment to continue. Meanwhile, the environment conditions indicate that the pedestrian is a male in his 30s, approximately 170 cm tall, wearing a black T-shirt and black slacks. The weather is clear and the brightness is bright. The road conditions are favorable, with a dry asphalt surface and a level incline. The road is a residential road with two-way traffic and without sidewalks on both sides or roadside strips on both sides. However, there are street lights illuminating the area. The overall situation seems calm and ordinary, with the vehicle and pedestrian being momentarily paused in their respective positions on the road.\",\n",
              "   'start_time': '4.093',\n",
              "   'end_time': '5.383'},\n",
              "  {'labels': ['1'],\n",
              "   'caption_pedestrian': \"The pedestrian, a male in his 30s, stood diagonally to the left in front of the vehicle. His body was perpendicular to the vehicle and to the right. He was approximately close to the vehicle, with a clear line of sight towards it. Slowly looking around, he was aware of the vehicle's presence. Dressed in a black T-shirt and slacks, he stood on a level and dry asphalt road. The weather was clear with bright lighting, and it was a usual day in terms of traffic volume. The event took place on a residential road with two-way traffic. There was no sidewalk on both sides, and neither the roadside strip nor the street lights were present. Despite this, the pedestrian was about to cross the road, moving slowly in the direction of travel in front of the vehicle.\",\n",
              "   'caption_vehicle': \"The vehicle is positioned diagonally to the right in front of the pedestrian, at a close relative distance. The pedestrian is clearly visible within the vehicle's field of view. The vehicle is about to stop and is moving at a speed of 5 km/h. The driver is aware of the pedestrian's presence and is taking necessary action to halt the vehicle. The event takes place in a clear weather condition with bright brightness. The vehicle is traveling on a residential road with two-way traffic and a dry asphalt surface. The surrounding environment indicates a male pedestrian in his 30s, standing at a height of 170 cm. He is wearing a black T-shirt and black slacks. The road does not have a sidewalk on both sides and there is no roadside strip. However, street lights are present, ensuring sufficient visibility. The traffic volume is normal and the road is level. All these factors provide the necessary context for the event involving the vehicle and the pedestrian.\",\n",
              "   'start_time': '1.066',\n",
              "   'end_time': '4.037'},\n",
              "  {'labels': ['0'],\n",
              "   'caption_pedestrian': \"The pedestrian, a male in his 30s, was standing diagonally to the left in front of the vehicle on a residential road. His body was oriented perpendicular to the vehicle and to the right. Positioned near the vehicle, his line of sight was directed towards his crossing destination. He was slowly looking around and dressed in a black T-shirt and slacks. The weather was clear and bright, with dry road surface conditions on the level asphalt road. Despite the usual traffic volume on the two-way street, there were no sidewalks or roadside strips available. However, street lights were present, ensuring visibility. The pedestrian's general action was going straight ahead, and his speed was slow. Overall, the pedestrian was actively observing his surroundings and preparing to cross the road, taking into account the environmental conditions and traffic situation.\",\n",
              "   'caption_vehicle': \"The vehicle is positioned diagonally to the right in front of the pedestrian, at a close distance. The pedestrian is visible within the vehicle's field of view. The vehicle is going straight ahead at a speed of 10 km/h. Meanwhile, in the environment, there is a male pedestrian in his 30s, standing at a height of 170 cm. He is wearing a black T-shirt and black slacks. The weather is clear with bright lighting, and the road surface is dry and level. The road is a residential road with two-way traffic and does not have sidewalks on both sides. There are no roadside strips, but the street lights are on. Overall, the vehicle is in a normal traffic situation, with clear visibility of the pedestrian and suitable road conditions for its speed and direction.\",\n",
              "   'start_time': '0.00',\n",
              "   'end_time': '1.066'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Archivo con procesamiento"
      ],
      "metadata": {
        "id": "LDpEh9jZwxu9"
      },
      "id": "LDpEh9jZwxu9"
    },
    {
      "cell_type": "code",
      "source": [
        "get_annotation('dataset/annotations_preprocess/20230707_12_SN17_T1_caption.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVE0FmfauQgs",
        "outputId": "185c8457-8862-4963-8325-08cdf1ece93f"
      },
      "id": "pVE0FmfauQgs",
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'vehicle_view': '20230707_12_SN17_T1_vehicle_view.mp4',\n",
              " 'event_phase': [{'labels': ['4'],\n",
              "   'caption_pedestrian': 'pedestrian male 30 approximately 170 cm tall wearing black tshirt black slack clear bright day dry road condition residential road twoway traffic sidewalk side street light present pedestrian positioned directly front vehicle facing opposite direction pedestrian noticed vehicle slowly moving front suddenly collision occurred',\n",
              "   'caption_vehicle': 'vehicle positioned front pedestrian close proximity vehicle clear field view pedestrian visible vehicle currently stopped speed 0 kmh gender pedestrian male 30 height 170 cm wearing black tshirt upper body black slack lower body weather clear brightness bright road surface condition dry road level asphalt traffic volume usual twoway residential road sidewalk side roadside strip street light present',\n",
              "   'start_time': '9.476',\n",
              "   'end_time': '14.017'},\n",
              "  {'labels': ['3'],\n",
              "   'caption_pedestrian': 'pedestrian male 30 stood perpendicular vehicle right directly front vehicle positioned closely line sight focused road surface indicating closely watching moving slowly pedestrian front vehicle appeared crossing wore black tshirt upper body black slack lower body weather clear bright brightness road surface dry leveled asphalt traffic volume twoway residential road usual side road sidewalk roadside strip street light set data provides detailed description pedestrian surrounding environment thirdperson narrative style',\n",
              "   'caption_vehicle': 'vehicle positioned right side pedestrian close proximity vehicle field view pedestrian visible vehicle going straight ahead speed 5 kmh environment condition include male pedestrian 30 standing height 170 cm wearing black tshirt upper body black slack lower body weather clear brightness bright road surface condition dry road level asphalt traffic volume usual residential road twoway traffic sidewalk available side roadside strip also absent street light present surroundings',\n",
              "   'start_time': '5.383',\n",
              "   'end_time': '9.420'},\n",
              "  {'labels': ['2'],\n",
              "   'caption_pedestrian': 'man 30 wearing black tshirt black slack stand diagonally left vehicle residential road body positioned perpendicular vehicle right man height approximately 170 cm weather clear brightness bright road surface dry level made asphalt twoway traffic lane sidewalk roadside strip side road street light illuminate surroundings despite noticing vehicle pedestrian moving slowly seems slowly looking around possibly unaware vehicle presence pedestrian cross road intending travel front vehicle traffic volume usual creating typical scenario pedestrian',\n",
              "   'caption_vehicle': 'vehicle positioned diagonally right front pedestrian close distance pedestrian visible within vehicle field view vehicle currently stopped speed 0 kmh driver observing surroundings waiting appropriate moment continue meanwhile environment condition indicate pedestrian male 30 approximately 170 cm tall wearing black tshirt black slack weather clear brightness bright road condition favorable dry asphalt surface level incline road residential road twoway traffic without sidewalk side roadside strip side however street light illuminating area overall situation seems calm ordinary vehicle pedestrian momentarily paused respective position road',\n",
              "   'start_time': '4.093',\n",
              "   'end_time': '5.383'},\n",
              "  {'labels': ['1'],\n",
              "   'caption_pedestrian': 'pedestrian male 30 stood diagonally left front vehicle body perpendicular vehicle right approximately close vehicle clear line sight towards slowly looking around aware vehicle presence dressed black tshirt slack stood level dry asphalt road weather clear bright lighting usual day term traffic volume event took place residential road twoway traffic sidewalk side neither roadside strip street light present despite pedestrian cross road moving slowly direction travel front vehicle',\n",
              "   'caption_vehicle': 'vehicle positioned diagonally right front pedestrian close relative distance pedestrian clearly visible within vehicle field view vehicle stop moving speed 5 kmh driver aware pedestrian presence taking necessary action halt vehicle event take place clear weather condition bright brightness vehicle traveling residential road twoway traffic dry asphalt surface surrounding environment indicates male pedestrian 30 standing height 170 cm wearing black tshirt black slack road sidewalk side roadside strip however street light present ensuring sufficient visibility traffic volume normal road level factor provide necessary context event involving vehicle pedestrian',\n",
              "   'start_time': '1.066',\n",
              "   'end_time': '4.037'},\n",
              "  {'labels': ['0'],\n",
              "   'caption_pedestrian': 'pedestrian male 30 standing diagonally left front vehicle residential road body oriented perpendicular vehicle right positioned near vehicle line sight directed towards crossing destination slowly looking around dressed black tshirt slack weather clear bright dry road surface condition level asphalt road despite usual traffic volume twoway street sidewalk roadside strip available however street light present ensuring visibility pedestrian general action going straight ahead speed slow overall pedestrian actively observing surroundings preparing cross road taking account environmental condition traffic situation',\n",
              "   'caption_vehicle': 'vehicle positioned diagonally right front pedestrian close distance pedestrian visible within vehicle field view vehicle going straight ahead speed 10 kmh meanwhile environment male pedestrian 30 standing height 170 cm wearing black tshirt black slack weather clear bright lighting road surface dry level road residential road twoway traffic sidewalk side roadside strip street light overall vehicle normal traffic situation clear visibility pedestrian suitable road condition speed direction',\n",
              "   'start_time': '0.00',\n",
              "   'end_time': '1.066'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "id": "IS64A_xzldZA",
      "metadata": {
        "id": "IS64A_xzldZA"
      },
      "outputs": [],
      "source": [
        "folder_preprocess_path = 'dataset/annotations_preprocess/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_data = []"
      ],
      "metadata": {
        "id": "P_ZCuWu01mp-"
      },
      "id": "P_ZCuWu01mp-",
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "id": "t8mmFhPrTe9z",
      "metadata": {
        "id": "t8mmFhPrTe9z"
      },
      "outputs": [],
      "source": [
        "for filename in os.listdir(folder_preprocess_path):\n",
        "  if filename.endswith('.json'):\n",
        "    filepath = os.path.join(folder_preprocess_path, filename)\n",
        "    with open(filepath, 'r') as f:\n",
        "      data = json.load(f)\n",
        "      for item in data['event_phase']:\n",
        "        preprocessed_data.append(item['caption_pedestrian'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_matrix = feature_engineering(preprocessed_data)"
      ],
      "metadata": {
        "id": "v6hKM56V2W7U"
      },
      "id": "v6hKM56V2W7U",
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_assigments = clustering(feature_matrix)"
      ],
      "metadata": {
        "id": "8GgAgdS42bIq"
      },
      "id": "8GgAgdS42bIq",
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cluster_assigments)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyNecbPX2gyz",
        "outputId": "f6357598-a4e7-4626-cde2-038b79cc5f27"
      },
      "id": "FyNecbPX2gyz",
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 3 3 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MalTd9Nq2PG4"
      },
      "id": "MalTd9Nq2PG4",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}